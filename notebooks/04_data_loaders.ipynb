{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA.data import loading_tools\n",
    "from JPAS_DA.data import cleaning_tools\n",
    "from JPAS_DA.data import crossmatch_tools\n",
    "from JPAS_DA.data import process_dset_splits\n",
    "from JPAS_DA.data import data_loaders\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/dlopez/Documentos/0.profesional/Postdoc/USP/Projects/JPAS_photozs/DATA/Train-Validate-Test\"\n",
    "\n",
    "load_JPAS_data = [{\n",
    "    \"name\": \"all\",\n",
    "    \"npy\": \"JPAS_DATA_Aper_Cor_3_FLUX+NOISE.npy\",\n",
    "    \"csv\": \"JPAS_DATA_PROPERTIES.csv\",\n",
    "    \"sample_percentage\": 1.0  # Optional, defaults to 1.0\n",
    "}]\n",
    "\n",
    "load_DESI_data = [\n",
    "{\n",
    "    \"name\": \"train\",\n",
    "    \"npy\": \"mock_3_train.npy\",\n",
    "    \"csv\": \"props_training.csv\",\n",
    "    \"sample_percentage\": 0.3\n",
    "},\n",
    "{\n",
    "    \"name\": \"val\",\n",
    "    \"npy\": \"mock_3_validate.npy\",\n",
    "    \"csv\": \"props_validate.csv\",\n",
    "    \"sample_percentage\": 1.0\n",
    "},\n",
    "{\n",
    "    \"name\": \"test\",\n",
    "    \"npy\": \"mock_3_test.npy\",\n",
    "    \"csv\": \"props_test.csv\",\n",
    "    \"sample_percentage\": 1.0\n",
    "}\n",
    "]\n",
    "\n",
    "random_seed_load = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = loading_tools.load_dsets(root_path=root_path, datasets_jpas=load_JPAS_data, datasets_desi=load_DESI_data, random_seed=random_seed_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_clean_data_options = {\n",
    "    \"apply_masks\"         : [\"unreliable\", \"magic_numbers\", \"negative_errors\", \"nan_values\", \"apply_additional_filters\"],\n",
    "    \"mask_indices\"        : [0, -2],\n",
    "    \"magic_numbers\"       : [-99, 99],\n",
    "    \"i_band_sn_threshold\" : 0,\n",
    "    \"z_lim_QSO_cut\"       : 2.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = cleaning_tools.clean_and_mask_data(\n",
    "    DATA=DATA,\n",
    "    apply_masks=dict_clean_data_options[\"apply_masks\"],\n",
    "    mask_indices=dict_clean_data_options[\"mask_indices\"],\n",
    "    magic_numbers=dict_clean_data_options[\"magic_numbers\"],\n",
    "    i_band_sn_threshold=dict_clean_data_options[\"i_band_sn_threshold\"],\n",
    "    z_lim_QSO_cut=dict_clean_data_options[\"z_lim_QSO_cut\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_LoA = {\"both\":{}, \"only\":{}} # Dictionary of Lists of Arrays (LoA) indicating, for each TARGETID, the associatted entries in the arrays, e.g. TARGETID[LoA[ii][0]] == TARGETID[LoA[ii][-1]]\n",
    "(\n",
    "    IDs_only_DESI, IDs_only_JPAS, IDs_both,\n",
    "    Dict_LoA[\"only\"][\"DESI\"], Dict_LoA[\"only\"][\"JPAS\"],\n",
    "    Dict_LoA[\"both\"][\"DESI\"], Dict_LoA[\"both\"][\"JPAS\"]\n",
    ") = crossmatch_tools.crossmatch_IDs_two_datasets(\n",
    "    DATA[\"DESI\"]['TARGETID'], DATA[\"JPAS\"]['TARGETID']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_data_options = {\n",
    "    \"train_ratio_both\"             : 0.8,\n",
    "    \"val_ratio_both\"               : 0.1,\n",
    "    \"test_ratio_both\"              : 0.1,\n",
    "    \"random_seed_split_both\"       : 42,\n",
    "    \"train_ratio_only_DESI\"        : 0.8,\n",
    "    \"val_ratio_only_DESI\"          : 0.1,\n",
    "    \"test_ratio_only_DESI\"         : 0.1,\n",
    "    \"random_seed_split_only_DESI\"  : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Lists of Arrays into training, validation, and testing sets\n",
    "Dict_LoA_split = {\"both\":{}, \"only\":{}}\n",
    "Dict_LoA_split[\"both\"][\"JPAS\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"both\"][\"JPAS\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_both\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_both\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_both\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_both\"]\n",
    ")\n",
    "Dict_LoA_split[\"both\"][\"DESI\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"both\"][\"DESI\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_both\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_both\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_both\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_both\"]\n",
    ")\n",
    "Dict_LoA_split[\"only\"][\"DESI\"]  = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"only\"][\"DESI\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_only_DESI\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_only_DESI\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_only_DESI\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_only_DESI\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_xx = ['OBS', 'ERR', 'MORPHTYPE_int']\n",
    "keys_yy = ['SPECTYPE_int', 'TARGETID']\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {\"DESI_combined\":{}, \"DESI_matched\":{}, \"JPAS_matched\":{}}\n",
    "provided_normalization = None\n",
    "for key_dset in [\"train\", \"val\", \"test\"]:\n",
    "    logging.info(f\"⚙️ Preparing split: {key_dset}\")\n",
    "\n",
    "    # DESI combined (only + matched)\n",
    "    logging.info(\"├── DESI_combined\")\n",
    "    LoA, xx, yy = process_dset_splits.extract_and_combine_DESI_data(\n",
    "        Dict_LoA_split[\"only\"][\"DESI\"][key_dset],\n",
    "        Dict_LoA_split[\"both\"][\"DESI\"][key_dset],\n",
    "        DATA[\"DESI\"], keys_xx, keys_yy\n",
    "    )\n",
    "    dset_loaders[\"DESI_combined\"][key_dset] = data_loaders.DataLoader(\n",
    "        xx, yy, normalize=normalize, provided_normalization=provided_normalization\n",
    "    )\n",
    "    if key_dset == \"train\":\n",
    "        provided_normalization = (\n",
    "            dset_loaders[\"DESI_combined\"][\"train\"].means,\n",
    "            dset_loaders[\"DESI_combined\"][\"train\"].stds\n",
    "        )\n",
    "\n",
    "    # DESI matched\n",
    "    logging.info(\"├── DESI_matched\")\n",
    "    LoA, xx, yy = process_dset_splits.extract_data_matched(\n",
    "        Dict_LoA_split[\"both\"][\"DESI\"][key_dset],\n",
    "        DATA[\"DESI\"], keys_xx, keys_yy\n",
    "    )\n",
    "    dset_loaders[\"DESI_matched\"][key_dset] = data_loaders.DataLoader(\n",
    "        xx, yy, normalize=normalize, provided_normalization=provided_normalization\n",
    "    )\n",
    "\n",
    "    # JPAS matched\n",
    "    logging.info(\"├── JPAS_matched\")\n",
    "    LoA, xx, yy = process_dset_splits.extract_data_matched(\n",
    "        Dict_LoA_split[\"both\"][\"JPAS\"][key_dset],\n",
    "        DATA[\"JPAS\"], keys_xx, keys_yy\n",
    "    )\n",
    "    dset_loaders[\"JPAS_matched\"][key_dset] = data_loaders.DataLoader(\n",
    "        xx, yy, normalize=normalize, provided_normalization=provided_normalization\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_dset in [\"train\", \"val\", \"test\"]:\n",
    "    print(key_dset)\n",
    "    tmp_DESI_TARGETID = dset_loaders[\"DESI_matched\"][key_dset].yy[\"TARGETID\"]\n",
    "    tmp_JPAS_TARGETID = dset_loaders[\"JPAS_matched\"][key_dset].yy[\"TARGETID\"]\n",
    "\n",
    "    print(tmp_DESI_TARGETID.shape)\n",
    "    print(tmp_JPAS_TARGETID.shape)\n",
    "\n",
    "    print(np.unique(tmp_DESI_TARGETID).shape)\n",
    "    print(np.unique(tmp_JPAS_TARGETID).shape)\n",
    "\n",
    "    print(np.array_equal(\n",
    "        np.sort(np.unique(tmp_DESI_TARGETID)),\n",
    "        np.sort(np.unique(tmp_JPAS_TARGETID))\n",
    "    ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
