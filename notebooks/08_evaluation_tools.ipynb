{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import data_loaders\n",
    "from JPAS_DA.data import generate_toy_data\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib inline\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Shared Parameters\n",
    "# =========================\n",
    "n_classes = 4\n",
    "class_proportions = np.array([0.2, 0.2, 0.55, 0.05])\n",
    "assert np.isclose(class_proportions.sum(), 1.0)\n",
    "\n",
    "# sample sizes\n",
    "n_samples_train    = 32768\n",
    "n_samples_val      = 32768\n",
    "n_samples_test     = 32768\n",
    "n_samples_train_DA = 1024\n",
    "n_samples_val_DA   = 1024\n",
    "\n",
    "# seeds\n",
    "seed_structure = 137\n",
    "seed_train     = 42\n",
    "seed_val       = 276\n",
    "seed_test      = 0\n",
    "seed_train_DA  = 1\n",
    "seed_val_DA    = 2\n",
    "seed_transform = 3\n",
    "\n",
    "# =========================\n",
    "# Create specs\n",
    "# =========================\n",
    "specs_target = [\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[0.0, 0.0], sigma=(1.5, 0.2), angle=np.pi/4),\n",
    "    ], weights=[1.0]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[-1.0, -1.0], sigma=(0.15, 0.9)),\n",
    "    ], weights=[1.0]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[2.5, 2.5], sigma=(0.6, 0.6)),\n",
    "        generate_toy_data.spec_gaussian(center=[-3.6, -2.0], sigma=(0.8, 0.8)),\n",
    "    ], weights=[0.7, 0.3]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_ring(center=[-3.5, -2.0], radius=1.1, width=0.05),\n",
    "    ], weights=[1.0]),\n",
    "]\n",
    "\n",
    "specs_source = [\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[0.0, -1.0], sigma=(0.9, 0.2)),\n",
    "    ], weights=[1.0]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[-1.0, -1.0], sigma=(0.15, 0.9)),\n",
    "    ], weights=[1.0]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_gaussian(center=[2.5, 2.5], sigma=(0.6, 0.6)),\n",
    "        generate_toy_data.spec_gaussian(center=[-3.5, -2.0], sigma=(0.4, 0.4)),\n",
    "    ], weights=[0.5, 0.5]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_ring(center=[-3.5, -2.0], radius=1.1, width=0.1),\n",
    "    ], weights=[1.0]),\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Generate Train/Val Source with the SAME shared specs and Target/Test with DIFFERENT shifted specs\n",
    "# =========================\n",
    "xx_train, yy_train, train_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_train, specs_source, class_proportions, seed=seed_train\n",
    ")\n",
    "xx_val, yy_val, val_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_val, specs_source, class_proportions, seed=seed_val\n",
    ")\n",
    "xx_test, yy_test, test_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_test, specs_target, class_proportions, seed=seed_test\n",
    ")\n",
    "xx_train_DA, yy_train_DA, _ = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_train_DA, specs_target, class_proportions, seed=seed_train_DA\n",
    ")\n",
    "xx_val_DA, yy_val_DA, _ = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_val_DA, specs_target, class_proportions, seed=seed_val_DA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_Supervised = os.path.join(global_setup.path_models, \"06_example_model_Supervised\")\n",
    "path_load_no_DA = os.path.join(global_setup.path_models, \"06_example_model\")\n",
    "path_load_DA = os.path.join(global_setup.path_models, \"07_example_model_DA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train_DA = data_loaders.DataLoader(xx_train_DA, yy_train_DA)\n",
    "dset_val_no_DA = data_loaders.DataLoader(xx_val, yy_val)\n",
    "dset_val_DA = data_loaders.DataLoader(xx_val_DA, yy_val_DA)\n",
    "dset_test = data_loaders.DataLoader(xx_test, yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_encoder_Supervised = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_Supervised, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_Supervised = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_Supervised, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_Supervised.eval()\n",
    "model_downstream_Supervised.eval()\n",
    "\n",
    "_, model_encoder_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_no_DA.eval()\n",
    "model_downstream_no_DA.eval()\n",
    "\n",
    "_, model_encoder_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_DA.eval()\n",
    "model_downstream_DA.eval()\n",
    "\n",
    "_ = evaluation_tools.compare_model_parameters(model_downstream_no_DA, model_downstream_DA, rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_Supervised(xx)\n",
    "        logits = model_downstream_Supervised(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test_Supervised = yy_true.cpu().numpy()\n",
    "features_test_Supervised= features_.cpu().numpy()\n",
    "yy_pred_P_test_Supervised = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_Supervised = np.argmax(yy_pred_P_test_Supervised, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_no_DA(batch_size=dset_val_no_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_no_DA = yy_true.cpu().numpy()\n",
    "features_val_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_no_DA = np.argmax(yy_pred_P_val_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_train_DA(batch_size=dset_train_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_train_DA = yy_true.cpu().numpy()\n",
    "features_train_DA = features_.cpu().numpy()\n",
    "yy_pred_P_train_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_train_DA = np.argmax(yy_pred_P_train_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_DA(batch_size=dset_val_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_DA = yy_true.cpu().numpy()\n",
    "features_val_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_DA = np.argmax(yy_pred_P_val_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_no_DA = np.argmax(yy_pred_P_test_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_DA = np.argmax(yy_pred_P_test_DA, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Subsampling options (set to None for no subsampling)\n",
    "# =========================\n",
    "SUBSAMPLE_SOURCE_VAL   = 0.15   # e.g., 0.2 for 20% per-class, or 500 for max 500 pts per class\n",
    "SUBSAMPLE_TARGET_TEST  = 0.15   # e.g., 0.2 or 500\n",
    "SUBSAMPLE_TARGET_TRAIN = 0.15   # optional: subsample DA-train overlay (panel 3)\n",
    "SUBSAMPLE_SEED         = 42\n",
    "\n",
    "rng = np.random.default_rng(SUBSAMPLE_SEED)\n",
    "\n",
    "def _select_indices_per_class(mask_bool, max_or_frac, rng):\n",
    "    \"\"\"\n",
    "    From a boolean mask, return a subset of indices.\n",
    "    - If max_or_frac is None -> all indices.\n",
    "    - If 0 < max_or_frac < 1 (float) -> that fraction of indices.\n",
    "    - If >=1 (int/float) -> up to that many indices (min with available).\n",
    "    \"\"\"\n",
    "    idx_all = np.flatnonzero(mask_bool)\n",
    "    if max_or_frac is None:\n",
    "        return idx_all\n",
    "    n = len(idx_all)\n",
    "    if n == 0:\n",
    "        return idx_all\n",
    "    if isinstance(max_or_frac, float) and 0 < max_or_frac < 1:\n",
    "        k = max(1, int(np.floor(n * max_or_frac)))\n",
    "    else:\n",
    "        k = min(n, int(max_or_frac))\n",
    "    return rng.choice(idx_all, size=k, replace=False)\n",
    "\n",
    "# =========================\n",
    "# Global style parameters\n",
    "# =========================\n",
    "FS_TICK         = 16  # tick labels\n",
    "FS_LABEL        = 20  # axis labels\n",
    "FS_BOX          = 15  # info box text\n",
    "FS_LEGEND       = 13  # legend text\n",
    "FS_LEGEND_TITLE = 14  # legend title\n",
    "FS_CBAR_LABEL   = 18  # colorbar label\n",
    "FS_CBAR_TICK    = 16  # colorbar ticks\n",
    "\n",
    "INFOBOX_BBOX = dict(boxstyle='round,pad=0.35', facecolor='white',\n",
    "                    alpha=0.9, edgecolor='black', linewidth=0.8)\n",
    "\n",
    "# =========================\n",
    "# Bounds & grid\n",
    "# =========================\n",
    "x_min, x_max = -6, 6\n",
    "y_min, y_max = -6, 6\n",
    "grid_res = 512\n",
    "\n",
    "xx_vals = np.linspace(x_min, x_max, grid_res)\n",
    "yy_vals = np.linspace(y_min, y_max, grid_res)\n",
    "xx_mesh, yy_mesh = np.meshgrid(xx_vals, yy_vals)\n",
    "grid_points = np.stack([xx_mesh.ravel(), yy_mesh.ravel()], axis=1)\n",
    "\n",
    "# Build the grid tensor on CPU, move to the model's device for each forward pass\n",
    "xx_grid_cpu = torch.tensor(grid_points, dtype=torch.float32, device=\"cpu\")\n",
    "\n",
    "# =========================\n",
    "# Colors (consistent across panels)\n",
    "# =========================\n",
    "class_labels = np.unique(dset_val_no_DA.yy[\"SPECTYPE_int\"])\n",
    "n_classes = len(class_labels)\n",
    "cmap_base = plt.cm.get_cmap(\"plasma\", n_classes)   # discretize plasma into N colors\n",
    "class_colors = [cmap_base(i) for i in range(n_classes)]\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(class_colors)\n",
    "norm = mpl.colors.BoundaryNorm(np.arange(n_classes + 1) - 0.5, ncolors=n_classes)\n",
    "\n",
    "# =========================\n",
    "# Helper: annotate panels (ONLY background info)\n",
    "# =========================\n",
    "def add_info_box(ax, bg_desc):\n",
    "    txt = f\"Background: {bg_desc}\"\n",
    "    ax.text(0.02, 0.98, txt, transform=ax.transAxes,\n",
    "            va='top', ha='left', fontsize=FS_BOX, bbox=INFOBOX_BBOX)\n",
    "\n",
    "# =========================\n",
    "# Helper: predict on grid\n",
    "# =========================\n",
    "def predict_grid(encoder, downstream, xx_grid_cpu, device):\n",
    "    with torch.no_grad():\n",
    "        feats = encoder(xx_grid_cpu.to(device))\n",
    "        logits = downstream(feats)\n",
    "        yy_pred = torch.softmax(logits, dim=1).argmax(dim=1)\n",
    "    Z = yy_pred.view(grid_res, grid_res).cpu().numpy().astype(float)\n",
    "    return Z\n",
    "\n",
    "# Devices (assume models are already on appropriate devices)\n",
    "dev_no_DA = next(model_encoder_no_DA.parameters()).device\n",
    "dev_DA    = next(model_encoder_DA.parameters()).device\n",
    "\n",
    "# =========================\n",
    "# Compute predicted grids\n",
    "# =========================\n",
    "Z_Supervised = predict_grid(model_encoder_Supervised, model_downstream_Supervised, xx_grid_cpu, dev_no_DA)  # NEW\n",
    "Z_noDA_val  = predict_grid(model_encoder_no_DA, model_downstream_no_DA, xx_grid_cpu, dev_no_DA)\n",
    "Z_noDA_test = Z_noDA_val  # same models; reuse prediction for test overlay\n",
    "Z_DA_test   = predict_grid(model_encoder_DA, model_downstream_DA, xx_grid_cpu, dev_DA)\n",
    "\n",
    "# =========================\n",
    "# Figure with THREE VERTICAL PANELS (shared axes)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 18), sharex=True, sharey=True)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.tick_params(labelsize=FS_TICK)\n",
    "\n",
    "# Left y-labels on all panels; shared x-label on the bottom\n",
    "for ax in axes:\n",
    "    ax.set_ylabel(r\"$\\mathrm{Feature~2}$\", fontsize=FS_LABEL)\n",
    "axes[-1].set_xlabel(r\"$\\mathrm{Feature~1}$\", fontsize=FS_LABEL)\n",
    "\n",
    "# =========================\n",
    "# Panel 0: no-DA + SOURCE (validation) points\n",
    "# =========================\n",
    "ax_val = axes[0]\n",
    "ax_val.pcolormesh(xx_mesh, yy_mesh, Z_noDA_val, cmap=cmap, norm=norm,\n",
    "                  shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    mask = (dset_val_no_DA.yy[\"SPECTYPE_int\"] == label)\n",
    "    idx_sel = _select_indices_per_class(mask, SUBSAMPLE_SOURCE_VAL, rng)\n",
    "    if idx_sel.size == 0:\n",
    "        continue\n",
    "    pts = dset_val_no_DA.xx[\"OBS\"][idx_sel]\n",
    "    ax_val.scatter(pts[:, 0], pts[:, 1], s=16, alpha=0.3, color=class_colors[i],\n",
    "                   edgecolor='black', linewidth=0.1)  # default marker 'o'\n",
    "\n",
    "add_info_box(ax_val, \"no-DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Panel 1: no-DA + TARGET (test) points\n",
    "# =========================\n",
    "ax_noDA_test = axes[1]\n",
    "ax_noDA_test.pcolormesh(xx_mesh, yy_mesh, Z_noDA_test, cmap=cmap, norm=norm,\n",
    "                        shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    mask = (dset_test.yy[\"SPECTYPE_int\"] == label)\n",
    "    idx_sel = _select_indices_per_class(mask, SUBSAMPLE_TARGET_TEST, rng)\n",
    "    if idx_sel.size == 0:\n",
    "        continue\n",
    "    pts = dset_test.xx[\"OBS\"][idx_sel]\n",
    "    ax_noDA_test.scatter(pts[:, 0], pts[:, 1], marker='s', s=16, alpha=0.3, color=class_colors[i],\n",
    "                         edgecolor='black', linewidth=0.1)\n",
    "\n",
    "add_info_box(ax_noDA_test, \"no-DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Panel 2: DA + TARGET (test) points + TARGET (train) points\n",
    "# =========================\n",
    "ax_DA_test = axes[2]\n",
    "ax_DA_test.pcolormesh(xx_mesh, yy_mesh, Z_DA_test, cmap=cmap, norm=norm,\n",
    "                      shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    # Target test (subsample)\n",
    "    mask_test = (dset_test.yy[\"SPECTYPE_int\"] == label)\n",
    "    idx_sel_test = _select_indices_per_class(mask_test, SUBSAMPLE_TARGET_TEST, rng)\n",
    "    if idx_sel_test.size:\n",
    "        pts_test = dset_test.xx[\"OBS\"][idx_sel_test]\n",
    "        ax_DA_test.scatter(pts_test[:, 0], pts_test[:, 1], marker='s', s=16, alpha=0.3, color=class_colors[i],\n",
    "                           edgecolor='black', linewidth=0.1)\n",
    "\n",
    "    # DA train (optional subsample)\n",
    "    mask_train = (dset_train_DA.yy[\"SPECTYPE_int\"] == label)\n",
    "    idx_sel_train = _select_indices_per_class(mask_train, SUBSAMPLE_TARGET_TRAIN, rng)\n",
    "    if idx_sel_train.size:\n",
    "        pts_train = dset_train_DA.xx[\"OBS\"][idx_sel_train]\n",
    "        ax_DA_test.scatter(pts_train[:, 0], pts_train[:, 1], marker='^', s=120, alpha=0.8, color=class_colors[i],\n",
    "                           edgecolor='black', linewidth=0.1)\n",
    "\n",
    "add_info_box(ax_DA_test, \"DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Marker legend (first subpanel only, black symbols, uniform size)\n",
    "# =========================\n",
    "from matplotlib.lines import Line2D\n",
    "marker_handles = [\n",
    "    Line2D([0], [0], marker='o', linestyle='None', color='black', markersize=8,\n",
    "           label='Source (Test) points'),\n",
    "    Line2D([0], [0], marker='s', linestyle='None', color='black', markersize=8,\n",
    "           label='Target (Test) points'),\n",
    "    Line2D([0], [0], marker='^', linestyle='None', color='black', markersize=8,\n",
    "           label='Target (Training) points'),\n",
    "]\n",
    "ax_val.legend(handles=marker_handles, loc='lower right',\n",
    "              title=\"Scatter markers\", title_fontsize=FS_LEGEND_TITLE,\n",
    "              fontsize=FS_LEGEND, fancybox=True, shadow=True, framealpha=0.9)\n",
    "\n",
    "# =========================\n",
    "# Shared colorbar on the RIGHT\n",
    "# =========================\n",
    "plt.tight_layout(rect=[0.0, 0.0, 0.85, 1.0])  # leave room for colorbar\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cax = fig.add_axes([0.88, 0.10, 0.03, 0.80])  # [left, bottom, width, height] in figure coords\n",
    "cbar = fig.colorbar(sm, cax=cax)\n",
    "cbar.set_label(\"Predicted Class\", fontsize=FS_CBAR_LABEL)\n",
    "cbar.ax.tick_params(labelsize=FS_CBAR_TICK)\n",
    "cbar.set_ticks(np.arange(n_classes))\n",
    "try:\n",
    "    cbar.set_ticklabels([str(lbl) for lbl in class_labels])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.savefig(os.path.join(global_setup.path_saved_figures, \"toy_distributions_tripanel.png\"),\n",
    "            format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.arange(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cm = {\n",
    "    \"Source (no-DA)\": {\n",
    "        \"y_true\": yy_true_val_no_DA,\n",
    "        \"y_pred\": yy_pred_P_val_no_DA,\n",
    "    },\n",
    "    \"Target (no-DA)\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_no_DA,\n",
    "    },\n",
    "    \"Target (DA)\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_DA,\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, axes = evaluation_tools.plot_confusion_matrices_grid(\n",
    "    dict_cases=dict_cm,\n",
    "    class_names=class_names, cmap=\"RdYlGn\",\n",
    "    figsize=(6, 15), ncols=1, nrows=3, fs_cell=10, fs_cell_diag=10,\n",
    "    save_path=os.path.join(global_setup.path_saved_figures, \"toy_model_confusion_matrices.pdf\"),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cmp = {\n",
    "    \"Source no-DA\": {\n",
    "        \"y_true\": yy_true_val_no_DA,\n",
    "        \"y_pred\": yy_pred_P_val_no_DA,\n",
    "        \"plot_kwargs\": {\"color\": \"royalblue\", \"label\": \"Source no-DA\"},\n",
    "    },\n",
    "    \"Target no-DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_no_DA,\n",
    "        \"plot_kwargs\": {\"color\": \"firebrick\", \"label\": \"JPAS Obs. no-DA\"},\n",
    "    },\n",
    "    \"Target DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_DA,\n",
    "        \"plot_kwargs\": {\"color\": \"green\", \"label\": \"JPAS Obs. DA\"},\n",
    "    },\n",
    "}\n",
    "fig, axes = evaluation_tools.compare_models_performance(\n",
    "    dict_cases=dict_cmp,\n",
    "    class_names=class_names,\n",
    "    title=None,\n",
    "    figsize=(5, 24),\n",
    "    palette=[\"grey\", \"royalblue\", \"firebrick\", \"darkorange\", \"green\"],\n",
    "    save_path=os.path.join(global_setup.path_saved_figures, \"toy_model_metrics_comparison.pdf\"),\n",
    "    include_metrics=(\"Accuracy\", \"Macro F1\", \"Macro TPR\", \"Macro Precision\", \"Macro AUROC\", \"ECE\"),\n",
    "    nrows=7,\n",
    "    subplot_hspace=-1.166,\n",
    "    subplot_wspace=0.25,\n",
    "    ylabel_text=\"Score\",\n",
    "    y_ranges={\n",
    "        \"Accuracy\":        (0.4, 1.2),\n",
    "        \"Macro F1\":        (0.55, 1.1),\n",
    "        \"Macro TPR\":       (0.6, 1.1),\n",
    "        \"Macro Precision\": (0.6, 1.05),\n",
    "        \"Macro AUROC\":     (0.85, 1.05),\n",
    "        \"ECE\":             (0.0, 0.5)\n",
    "    },\n",
    "    y_margin_frac=0.07,\n",
    "    bar_alpha=0.9,\n",
    "    bar_edgecolor=\"black\",\n",
    "    bar_width=0.7,\n",
    "    annotate_values=True,\n",
    "    value_label_fontsize=12,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = evaluation_tools.compare_models_performance_per_class(\n",
    "    dict_cases=dict_cmp, class_names=class_names, title=None,\n",
    "    figsize=(9, 25),\n",
    "    palette=[\"grey\", \"royalblue\", \"firebrick\", \"darkorange\", \"green\"],\n",
    "    save_path=None, #os.path.join(global_setup.path_saved_figures, \"toy_model_metrics_comparison_per_class.pdf\"),\n",
    "    include_metrics=(\"Accuracy\", \"F1\", \"TPR\", \"Precision\", \"AUROC\", \"ECE\", \"Brier\"),\n",
    "    nrows=7, subplot_hspace=0.5, subplot_wspace=0.25,\n",
    "    y_ranges={\n",
    "        \"Accuracy\":  (-0.2, 1.2),\n",
    "        \"F1\":        (-0.2, 1.2),\n",
    "        \"TPR\":       (-0.2, 1.2),\n",
    "        \"Precision\": (-0.2, 1.2),\n",
    "        \"AUROC\":     (-0.2, 1.2),\n",
    "        \"ECE\":       (-0.2, 1.2),\n",
    "        \"Brier\":     (-0.2, 1.2),\n",
    "    },\n",
    "    y_margin_frac=0.07, bar_alpha=0.9, bar_edgecolor=\"black\", group_width=0.9,\n",
    "    annotate_values=True, value_label_fontsize=9, ylabel_text=\"Score\", left_margin=0.10,\n",
    "    ytick_step=0.05, ytick_format=\"{x:.2f}\", two_line_class_xticklabels=False,\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_radar = {\n",
    "    \"Source no-DA\": {\n",
    "        \"y_true\": yy_true_val_no_DA,\n",
    "        \"y_pred\": yy_pred_P_val_no_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"--\", \"linewidth\": 2.0, \"color\": \"royalblue\",\n",
    "            \"marker\": \"s\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Source no-DA\",\n",
    "        },\n",
    "    },\n",
    "    \"Target no-DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_no_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"--\", \"linewidth\": 2.0, \"color\": \"firebrick\",\n",
    "            \"marker\": \"v\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Target no-DA\",\n",
    "        },\n",
    "    },\n",
    "    \"Target DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-\", \"linewidth\": 2.0, \"color\": \"green\",\n",
    "            \"marker\": \"o\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Target DA\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, ax = evaluation_tools.radar_plot(\n",
    "    dict_radar=dict_radar,\n",
    "    class_names=class_names,\n",
    ")\n",
    "fig.savefig(os.path.join(global_setup.path_saved_figures, \"toy_model_F1_radar.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_roc = {\n",
    "    \"Target no-DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_no_DA,\n",
    "        \"plot_kwargs\": {\"linestyle\": \"--\", \"linewidth\": 2.0, \"marker\": None, \"markersize\": 8,\n",
    "                        \"label\": \"Target no-DA\"},\n",
    "    },\n",
    "    \"Target DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_DA,\n",
    "        \"plot_kwargs\": {\"linestyle\": \"-\", \"linewidth\": 2.0, \"marker\": None, \"markersize\": 8,\n",
    "                        \"label\": \"Target DA\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, ax = evaluation_tools.plot_multiclass_rocs(\n",
    "    dict_cases=dict_roc,\n",
    "    class_names=class_names,\n",
    "    title=None,\n",
    "    x_lims=(-0.05, 0.5),\n",
    "    y_lims=(0.5, 1.05),\n",
    ")\n",
    "ax.axhline(1, color=\"grey\", linestyle=\":\", linewidth=1.0)\n",
    "ax.axvline(0, color=\"grey\", linestyle=\":\", linewidth=1.0)\n",
    "fig.savefig(os.path.join(global_setup.path_saved_figures, \"toy_model_ROC.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "    \"latents_no_DA_Source\": features_val_no_DA,\n",
    "    \"latents_no_DA_Target\": features_test_no_DA,\n",
    "    \"latents_DA_Target\": features_test_DA\n",
    "}\n",
    "\n",
    "latents_tSNE = evaluation_tools.tsne_per_key(\n",
    "    feat_dict,\n",
    "    standardize=False,\n",
    "    subsample=None,\n",
    "    random_state=137,\n",
    "    tsne_kwargs={\"perplexity\": 100},\n",
    "    return_all_key=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-150, 150)\n",
    "ylim = (-150, 150)\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Source_tSNE'], y_val=yy_true_val_no_DA,\n",
    "    X_test=latents_tSNE['latents_no_DA_Target_tSNE'], y_test=yy_true_test,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Source vs Target\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=14, size_test=14, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=4000, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Source no-DA\",\n",
    "    legend_split_2=\"Target no-DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'], yy_pred_val_no_DA, # yy_true_val_no_DA\n",
    "    class_counts=dset_val_no_DA.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Source\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'],\n",
    "    title=\"Latents no-DA: Source\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'], yy_pred_test_no_DA, # yy_true_test\n",
    "    class_counts=dset_test.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Target\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'],\n",
    "    title=\"Latents no-DA: Target\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Target_tSNE'], y_val=yy_true_test,\n",
    "    X_test=latents_tSNE['latents_DA_Target_tSNE'], y_test=yy_true_test,\n",
    "    class_names=None,\n",
    "    title=\"Latents Target: no-DA vs DA\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=14, size_test=14, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=4000, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Target no-DA\",\n",
    "    legend_split_2=\"Target DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'], yy_pred_test_DA, # yy_true_test\n",
    "    class_counts=dset_test.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents DA: Target\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'],\n",
    "    title=\"Latents DA: Target\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
