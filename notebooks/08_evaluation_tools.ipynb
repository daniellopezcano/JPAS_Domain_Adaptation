{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import data_loaders\n",
    "from JPAS_DA.data import generate_toy_data\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib inline\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Shared Parameters\n",
    "# =========================\n",
    "n_classes = 5\n",
    "class_proportions = np.array([0.55, 0.05, 0.05, 0.25, 0.10])\n",
    "assert np.isclose(class_proportions.sum(), 1.0)\n",
    "\n",
    "# sample sizes\n",
    "n_samples_train    = 16384\n",
    "n_samples_val      = 16384\n",
    "n_samples_test     = 16384\n",
    "n_samples_train_DA = 64\n",
    "n_samples_val_DA   = 1024\n",
    "\n",
    "# seeds\n",
    "seed_structure = 137\n",
    "seed_train     = 42\n",
    "seed_val       = 276\n",
    "seed_test      = 0\n",
    "seed_train_DA  = 1\n",
    "seed_val_DA    = 2\n",
    "seed_transform = 3\n",
    "\n",
    "# =========================\n",
    "# Create specs\n",
    "# =========================\n",
    "specs_target = [\n",
    "    generate_toy_data.spec_gaussian(center=[-1.0, 3.7], sigma=(1.1, 0.5)),\n",
    "    generate_toy_data.spec_spline(control_points=[[3.8,-3.8], [6,-6], [-7,-7], [-5,-2], [0,0], [2,1], [7,8]],\n",
    "                thickness=0.4, jitter=0.05, closed=False),\n",
    "    generate_toy_data.spec_spiral(center=[0,0], a=0.8, b=6.0, turns=1.5, theta0=2*np.pi,\n",
    "                radial_noise=0.2, jitter=0.05),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_ring(center=[5.5,6.6], radius=2., width=0.2, arc=(0.0, 2*np.pi), jitter=0.1),\n",
    "        generate_toy_data.spec_gaussian(center=[-3,-4], sigma=(0.5, 0.5)),\n",
    "    ], weights=[0.1, 0.9]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_spline(control_points=[[-4,2], [-6, -1], [-8,-1], [-8,2], [-6, 6], [-2, 7], [1, 7]],\n",
    "            thickness=0.4, jitter=0.05, closed=False),\n",
    "        generate_toy_data.spec_gaussian(center=[-2,-8], sigma=(1.0, 0.3)),\n",
    "    ], weights=[0.5, 0.5])\n",
    "]\n",
    "\n",
    "specs_source = [\n",
    "    generate_toy_data.spec_gaussian(center=[1.7, 3.5], sigma=(0.4, 0.8)),\n",
    "    generate_toy_data.spec_spline(control_points=[[3.8,-3.8], [6,-6], [-7,-7], [-5,-2], [0,0], [2,1], [7,8]],\n",
    "                thickness=0.2, jitter=0.05, closed=False),\n",
    "    generate_toy_data.spec_spiral(center=[0,0], a=0.8, b=6.0, turns=1.5, theta0=2*np.pi,\n",
    "                radial_noise=0.1, jitter=0.1),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_ring(center=[5.5,6.5], radius=2.2, width=0.1, arc=(0.0, 2*np.pi), jitter=0.05),\n",
    "        generate_toy_data.spec_gaussian(center=[-2,-5], sigma=(0.3, 0.5)),\n",
    "    ], weights=[0.1, 0.9]),\n",
    "    generate_toy_data.spec_mixture([\n",
    "        generate_toy_data.spec_spline(control_points=[[-4,2], [-6, -1], [-8,-1], [-8,2], [-6, 6], [-2, 7], [1, 7]],\n",
    "            thickness=0.2, jitter=0.05, closed=False),\n",
    "        generate_toy_data.spec_gaussian(center=[-4.5,-8.], sigma=(1.5, 1.2)),\n",
    "    ], weights=[0.5, 0.5])\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Generate Train/Val Source with the SAME shared specs and Target/Test with DIFFERENT shifted specs\n",
    "# =========================\n",
    "xx_train, yy_train, train_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_train, specs_source, class_proportions, seed=seed_train\n",
    ")\n",
    "xx_val, yy_val, val_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_val, specs_source, class_proportions, seed=seed_val\n",
    ")\n",
    "xx_test, yy_test, test_counts = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_test, specs_target, class_proportions, seed=seed_test\n",
    ")\n",
    "xx_train_DA, yy_train_DA, _ = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_train_DA, specs_target, class_proportions, seed=seed_train_DA\n",
    ")\n",
    "xx_val_DA, yy_val_DA, _ = generate_toy_data.generate_dataset_from_specs(\n",
    "    n_samples_val_DA, specs_target, class_proportions, seed=seed_val_DA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_Fully_Supervised = os.path.join(global_setup.path_models, \"06_example_model_Fully_Supervised\")\n",
    "path_load_no_DA = os.path.join(global_setup.path_models, \"06_example_model\")\n",
    "path_load_DA = os.path.join(global_setup.path_models, \"07_example_model_DA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train_DA = data_loaders.DataLoader(xx_train_DA, yy_train_DA)\n",
    "dset_val_no_DA = data_loaders.DataLoader(xx_val, yy_val)\n",
    "dset_val_DA = data_loaders.DataLoader(xx_val_DA, yy_val_DA)\n",
    "dset_test = data_loaders.DataLoader(xx_test, yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_encoder_Fully_Supervised = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_Fully_Supervised, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_Fully_Supervised = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_Fully_Supervised, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_Fully_Supervised.eval()\n",
    "model_downstream_Fully_Supervised.eval()\n",
    "\n",
    "_, model_encoder_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_no_DA.eval()\n",
    "model_downstream_no_DA.eval()\n",
    "\n",
    "_, model_encoder_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "model_encoder_DA.eval()\n",
    "model_downstream_DA.eval()\n",
    "\n",
    "_ = evaluation_tools.compare_model_parameters(model_downstream_no_DA, model_downstream_DA, rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_Fully_Supervised(xx)\n",
    "        logits = model_downstream_Fully_Supervised(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test_Fully_Supervised = yy_true.cpu().numpy()\n",
    "features_test_Fully_Supervised= features_.cpu().numpy()\n",
    "yy_pred_P_test_Fully_Supervised = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_Fully_Supervised = np.argmax(yy_pred_P_test_Fully_Supervised, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_no_DA(batch_size=dset_val_no_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_no_DA = yy_true.cpu().numpy()\n",
    "features_val_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_no_DA = np.argmax(yy_pred_P_val_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_train_DA(batch_size=dset_train_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_train_DA = yy_true.cpu().numpy()\n",
    "features_train_DA = features_.cpu().numpy()\n",
    "yy_pred_P_train_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_train_DA = np.argmax(yy_pred_P_train_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_DA(batch_size=dset_val_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_DA = yy_true.cpu().numpy()\n",
    "features_val_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_DA = np.argmax(yy_pred_P_val_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_no_DA = np.argmax(yy_pred_P_test_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_DA = np.argmax(yy_pred_P_test_DA, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Global style parameters\n",
    "# =========================\n",
    "FS_TICK         = 16  # tick labels\n",
    "FS_LABEL        = 20  # axis labels\n",
    "FS_BOX          = 15  # info box text\n",
    "FS_LEGEND       = 13  # legend text\n",
    "FS_LEGEND_TITLE = 14  # legend title\n",
    "FS_CBAR_LABEL   = 18  # colorbar label\n",
    "FS_CBAR_TICK    = 16  # colorbar ticks\n",
    "\n",
    "INFOBOX_BBOX = dict(boxstyle='round,pad=0.35', facecolor='white',\n",
    "                    alpha=0.9, edgecolor='black', linewidth=0.8)\n",
    "\n",
    "# =========================\n",
    "# Bounds & grid\n",
    "# =========================\n",
    "x_min, x_max = -10, 10\n",
    "y_min, y_max = -10, 10\n",
    "grid_res = 512\n",
    "\n",
    "xx_vals = np.linspace(x_min, x_max, grid_res)\n",
    "yy_vals = np.linspace(y_min, y_max, grid_res)\n",
    "xx_mesh, yy_mesh = np.meshgrid(xx_vals, yy_vals)\n",
    "grid_points = np.stack([xx_mesh.ravel(), yy_mesh.ravel()], axis=1)\n",
    "\n",
    "# Build the grid tensor on CPU, move to the model's device for each forward pass\n",
    "xx_grid_cpu = torch.tensor(grid_points, dtype=torch.float32, device=\"cpu\")\n",
    "\n",
    "# =========================\n",
    "# Colors (consistent across panels)\n",
    "# =========================\n",
    "try:\n",
    "    n_classes = len(dset_val_no_DA.class_labels)\n",
    "    class_labels = np.array(dset_val_no_DA.class_labels)\n",
    "    class_colors = [color_dict[int(i)] for i in range(n_classes)]\n",
    "except Exception:\n",
    "    class_labels = np.unique(dset_val_no_DA.yy[\"SPECTYPE_int\"])\n",
    "    n_classes = len(class_labels)\n",
    "    cmap_base = plt.cm.get_cmap(\"tab10\")\n",
    "    class_colors = [cmap_base(i % cmap_base.N) for i in range(n_classes)]\n",
    "\n",
    "cmap = mpl.colors.ListedColormap(class_colors)\n",
    "norm = mpl.colors.BoundaryNorm(np.arange(n_classes + 1) - 0.5, ncolors=n_classes)\n",
    "\n",
    "# Helper to annotate panels\n",
    "def add_info_box(ax, scatter_desc, bg_desc):\n",
    "    txt = f\"Scatter-Points: {scatter_desc}\\nBackground Predictions: {bg_desc}\"\n",
    "    ax.text(0.02, 0.98, txt, transform=ax.transAxes,\n",
    "            va='top', ha='left', fontsize=FS_BOX, bbox=INFOBOX_BBOX)\n",
    "\n",
    "# =========================\n",
    "# Helper: predict on grid\n",
    "# =========================\n",
    "def predict_grid(encoder, downstream, xx_grid_cpu, device):\n",
    "    with torch.no_grad():\n",
    "        feats = encoder(xx_grid_cpu.to(device))\n",
    "        logits = downstream(feats)\n",
    "        yy_pred = torch.softmax(logits, dim=1).argmax(dim=1)\n",
    "    Z = yy_pred.view(grid_res, grid_res).cpu().numpy().astype(float)\n",
    "    return Z\n",
    "\n",
    "# Devices (assume models are already on appropriate devices)\n",
    "dev_no_DA = next(model_encoder_no_DA.parameters()).device\n",
    "dev_DA    = next(model_encoder_DA.parameters()).device\n",
    "\n",
    "# =========================\n",
    "# Compute predicted grids\n",
    "# =========================\n",
    "Z_Fully_Supervised = predict_grid(model_encoder_Fully_Supervised, model_downstream_Fully_Supervised, xx_grid_cpu, dev_no_DA)  # NEW\n",
    "Z_noDA_val  = predict_grid(model_encoder_no_DA, model_downstream_no_DA, xx_grid_cpu, dev_no_DA)\n",
    "Z_noDA_test = Z_noDA_val  # same models; reuse prediction for test overlay\n",
    "Z_DA_test   = predict_grid(model_encoder_DA, model_downstream_DA, xx_grid_cpu, dev_DA)\n",
    "\n",
    "# =========================\n",
    "# Figure with FOUR VERTICAL PANELS (shared axes)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(4, 1, figsize=(8, 24), sharex=True, sharey=True)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.tick_params(labelsize=FS_TICK)\n",
    "\n",
    "# Left y-labels on all panels; shared x-label on the bottom\n",
    "for ax in axes:\n",
    "    ax.set_ylabel(r\"$\\mathrm{Feature~2}$\", fontsize=FS_LABEL)\n",
    "axes[-1].set_xlabel(r\"$\\mathrm{Feature~1}$\", fontsize=FS_LABEL)\n",
    "\n",
    "# =========================\n",
    "# Panel 0 (TOP): Fully_Supervised + train-DA points\n",
    "# =========================\n",
    "ax_train = axes[0]\n",
    "pcm_train = ax_train.pcolormesh(xx_mesh, yy_mesh, Z_Fully_Supervised, cmap=cmap, norm=norm,\n",
    "                                shading='nearest', alpha=0.5)\n",
    "for i, label in enumerate(class_labels):\n",
    "\n",
    "    mask = (dset_test.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_test.xx[\"OBS\"][mask]\n",
    "    ax_train.scatter(tmp[:, 0], tmp[:, 1], marker='s', s=12, alpha=0.5, color=class_colors[i],\n",
    "                       edgecolor='black', linewidth=0.1)\n",
    "    \n",
    "    mask = (dset_train_DA.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_train_DA.xx[\"OBS\"][mask]\n",
    "    ax_train.scatter(tmp[:, 0], tmp[:, 1], marker='^', s=120, alpha=1.0, color=class_colors[i],\n",
    "                     edgecolor='black', linewidth=0.1)\n",
    "\n",
    "add_info_box(ax_train, \"Target (Training) Set\", \"Fully_Supervised Model\")\n",
    "\n",
    "# =========================\n",
    "# Panel 1: no-DA + validation points + shared centers (only)\n",
    "# =========================\n",
    "ax_val = axes[1]\n",
    "pcm_val = ax_val.pcolormesh(xx_mesh, yy_mesh, Z_noDA_val, cmap=cmap, norm=norm,\n",
    "                            shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    mask = (dset_val_no_DA.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_val_no_DA.xx[\"OBS\"][mask]\n",
    "    ax_val.scatter(tmp[:, 0], tmp[:, 1], s=12, alpha=0.5, color=class_colors[i],\n",
    "                   edgecolor='black', linewidth=0.1)\n",
    "\n",
    "# Use \"Source (Validation) Set\" since this panel is validation points\n",
    "add_info_box(ax_val, \"Source (Validation) Set\", \"no-DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Panel 2: no-DA + test points + centers + arrows\n",
    "# =========================\n",
    "ax_noDA_test = axes[2]\n",
    "pcm_noDA_test = ax_noDA_test.pcolormesh(xx_mesh, yy_mesh, Z_noDA_test, cmap=cmap, norm=norm,\n",
    "                                        shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    mask = (dset_test.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_test.xx[\"OBS\"][mask]\n",
    "    ax_noDA_test.scatter(tmp[:, 0], tmp[:, 1], marker='s', s=12, alpha=0.5, color=class_colors[i],\n",
    "                         edgecolor='black', linewidth=0.1)\n",
    "\n",
    "add_info_box(ax_noDA_test, \"Target (Test) Set\", \"no-DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Panel 3: DA + test points + centers + arrows\n",
    "# =========================\n",
    "ax_DA_test = axes[3]\n",
    "pcm_DA_test = ax_DA_test.pcolormesh(xx_mesh, yy_mesh, Z_DA_test, cmap=cmap, norm=norm,\n",
    "                                    shading='nearest', alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "\n",
    "    mask = (dset_test.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_test.xx[\"OBS\"][mask]\n",
    "    ax_DA_test.scatter(tmp[:, 0], tmp[:, 1], marker='s', s=12, alpha=0.5, color=class_colors[i],\n",
    "                       edgecolor='black', linewidth=0.1)\n",
    "\n",
    "    mask = (dset_train_DA.yy[\"SPECTYPE_int\"] == label)\n",
    "    tmp = dset_train_DA.xx[\"OBS\"][mask]\n",
    "    ax_DA_test.scatter(tmp[:, 0], tmp[:, 1], marker='^', s=120, alpha=1.0, color=class_colors[i],\n",
    "                     edgecolor='black', linewidth=0.1)\n",
    "\n",
    "add_info_box(ax_DA_test, \"Target (Test) Set\", \"DA Model\")\n",
    "\n",
    "# =========================\n",
    "# Legends\n",
    "# =========================\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Class legend on top panel\n",
    "class_handles = [\n",
    "    Line2D([0], [0], marker='o', linestyle='None', markerfacecolor=class_colors[i],\n",
    "           markeredgecolor='black', markersize=8, label=str(class_labels[i]))\n",
    "    for i in range(n_classes)\n",
    "]\n",
    "leg_classes = ax_train.legend(handles=class_handles, loc='lower left',\n",
    "                              title=\"Class (points)\", title_fontsize=FS_LEGEND_TITLE,\n",
    "                              fontsize=FS_LEGEND, fancybox=True, shadow=True, framealpha=0.9)\n",
    "ax_train.add_artist(leg_classes)\n",
    "\n",
    "# =========================\n",
    "# Shared colorbar on the RIGHT\n",
    "# =========================\n",
    "plt.tight_layout(rect=[0.0, 0.0, 0.85, 1.0])  # leave room for colorbar\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cax = fig.add_axes([0.88, 0.10, 0.03, 0.80])  # [left, bottom, width, height] in figure coords\n",
    "cbar = fig.colorbar(sm, cax=cax)\n",
    "cbar.set_label(\"Predicted Class\", fontsize=FS_CBAR_LABEL)\n",
    "cbar.ax.tick_params(labelsize=FS_CBAR_TICK)\n",
    "cbar.set_ticks(np.arange(n_classes))\n",
    "try:\n",
    "    cbar.set_ticklabels([str(lbl) for lbl in class_labels])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.savefig(os.path.join(global_setup.path_saved_figures, \"toy_distributions_quadpanel.png\"),\n",
    "            format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Bigger font config ----\n",
    "FS_TITLE = 24\n",
    "FS_LABEL = 20\n",
    "FS_TICKS = 18\n",
    "FS_CELL  = 14          # off-diagonal cell text\n",
    "FS_CELL_DIAG = 14      # diagonal cell text\n",
    "FS_CBAR_LABEL = 20\n",
    "FS_CBAR_TICKS = 16\n",
    "TICK_ROT = 20\n",
    "\n",
    "# Config\n",
    "class_names = np.arange(n_classes)  # or your custom names\n",
    "cmap = plt.cm.RdYlGn\n",
    "threshold_color = 0.5  # cell text color threshold based on cm_percent (0..1)\n",
    "\n",
    "cases = [\n",
    "    (\"Fully_Supervised: Target\", yy_true_test,   yy_pred_P_test_Fully_Supervised),\n",
    "    (\"no DA: Source\", yy_true_val_no_DA, yy_pred_P_val_no_DA),\n",
    "    (\"no DA: Target\", yy_true_test,     yy_pred_P_test_no_DA),\n",
    "    (\"DA: Target\",    yy_true_test,     yy_pred_P_test_DA),\n",
    "]\n",
    "\n",
    "# Color normalization for row-normalized proportion in [0, 1]\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "\n",
    "# --- Three VERTICAL subpanels with shared axes ---\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 30), sharex=True, sharey=True)\n",
    "fig.dpi = 150\n",
    "\n",
    "# For shared colorbar\n",
    "mappable_for_cbar = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "mappable_for_cbar.set_array([])\n",
    "\n",
    "# Shared limits/ticks for confusion matrices (note reversed y-limits to keep row 0 at top)\n",
    "xlim = (-0.5, n_classes - 0.5)\n",
    "ylim = (n_classes - 0.5, -0.5)  # reverse to match origin='upper'\n",
    "ticks = np.arange(n_classes)\n",
    "\n",
    "for ax, (title, yy_true, yy_pred_P) in zip(axes, cases):\n",
    "    yy_pred = np.argmax(yy_pred_P, axis=1)\n",
    "\n",
    "    # Confusion matrix with all classes present\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    valid = (yy_true >= 0) & (yy_true < n_classes)\n",
    "    for t, p in zip(yy_true[valid], yy_pred[valid]):\n",
    "        cm[int(t), int(p)] += 1\n",
    "\n",
    "    # Row-normalized\n",
    "    row_sums = cm.sum(axis=1, keepdims=True)\n",
    "    cm_percent = np.divide(cm, row_sums, where=row_sums != 0)\n",
    "\n",
    "    # Matrix image (keep row 0 at the TOP)\n",
    "    im = ax.imshow(cm_percent, interpolation='nearest', cmap=cmap, norm=norm, origin='upper')\n",
    "\n",
    "    # Shared axes styling\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(class_names, fontsize=FS_TICKS)\n",
    "    ax.set_yticklabels(class_names, fontsize=FS_TICKS)\n",
    "    ax.set_aspect('equal', adjustable='box')  # square cells\n",
    "\n",
    "    # Place the \"title\" on the RIGHT like a y-label\n",
    "    ax.text(1.02, 0.5, title, transform=ax.transAxes,\n",
    "            rotation=-90, va='center', ha='left', fontsize=FS_TITLE)\n",
    "\n",
    "    # Per-class metrics\n",
    "    precision = np.zeros(n_classes, dtype=float)\n",
    "    recall    = np.zeros(n_classes, dtype=float)\n",
    "    f1        = np.zeros(n_classes, dtype=float)\n",
    "    for i in range(n_classes):\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall[i]    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1[i]        = (2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "                        if (precision[i] + recall[i]) > 0 else 0.0)\n",
    "\n",
    "    # Cell annotations (counts + %; diagonal shows TPR/PPV/F1)\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            count   = cm[i, j]\n",
    "            percent = cm_percent[i, j] * 100 if row_sums[i, 0] != 0 else 0.0\n",
    "            text_color = \"white\" if cm_percent[i, j] > threshold_color else \"black\"\n",
    "\n",
    "            if i == j:\n",
    "                text = (f\"{count}\\n\"\n",
    "                        f\"TPR:{recall[i]*100:.1f}% \"\n",
    "                        f\"\\nPPV:{precision[i]*100:.1f}% \"\n",
    "                        f\"\\nF1:{f1[i]:.2f}\")\n",
    "                ax.text(j, i, text, ha=\"center\", va=\"center\",\n",
    "                        color=text_color, fontsize=FS_CELL_DIAG, fontweight='bold', linespacing=1.2)\n",
    "            else:\n",
    "                text = f\"{count}\\n{percent:.1f}%\"\n",
    "                ax.text(j, i, text, ha=\"center\", va=\"center\",\n",
    "                        color=text_color, fontsize=FS_CELL, linespacing=1.2)\n",
    "\n",
    "# Labels: show y-label on middle panel, x-label on bottom panel\n",
    "axes[0].set_ylabel('True Label', fontsize=FS_LABEL, labelpad=10)\n",
    "axes[1].set_ylabel('True Label', fontsize=FS_LABEL, labelpad=10)\n",
    "axes[2].set_ylabel('True Label', fontsize=FS_LABEL, labelpad=10)\n",
    "plt.setp(axes[0].get_xticklabels(), visible=False)\n",
    "plt.setp(axes[1].get_xticklabels(), visible=False)\n",
    "axes[-1].set_xlabel('Predicted Label', fontsize=FS_LABEL, labelpad=10)\n",
    "plt.setp(axes[-1].get_xticklabels(), rotation=TICK_ROT, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Shared colorbar on the RIGHT\n",
    "plt.tight_layout(rect=[0.0, 0.0, 0.90, 1.0])  # leave room for cbar\n",
    "cax = fig.add_axes([0.92, 0.12, 0.02, 0.76])\n",
    "cbar = fig.colorbar(mappable_for_cbar, cax=cax)\n",
    "cbar.set_label(\"True-label (row) normalized ratio\", fontsize=FS_CBAR_LABEL)\n",
    "cbar.ax.tick_params(labelsize=FS_CBAR_TICKS)\n",
    "cbar.set_ticks([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "plt.savefig(os.path.join(global_setup.path_saved_figures, \"toy_confusion_matrices_tripanel.pdf\"),\n",
    "            bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_val_no_DA, yy_pred_P_val_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"no DA: Source\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"no DA: Target\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_val_DA, yy_pred_P_val_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"DA: Validation Set Target\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"DA: Target\"\n",
    ")\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    yy_true_val_no_DA,\n",
    "    yy_pred_P_val_no_DA,\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='TPR Comparison: Source vs Target (no-DA)',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\"\n",
    ")\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_no_DA,\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='TPR Comparison: DA vs no-DA (Target)',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy_true_val_no_DA, yy_pred_P_val_no_DA,\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    name_1=\"Source (no-DA)\",\n",
    "    name_2=\"Target\",\n",
    "    y_max_Delta_F1=1.0,\n",
    "    y_min_Delta_F1=-1.0,\n",
    "    f1_save_path=os.path.join(global_setup.path_saved_figures, \"toy_F1_comparison_source_vs_target_no_DA.pdf\")\n",
    ")\n",
    "\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    name_1=\"no-DA (Target)\",\n",
    "    name_2=\"DA\",\n",
    "    y_max_Delta_F1=1.0,\n",
    "    y_min_Delta_F1=-1.0,\n",
    "    f1_save_path=os.path.join(global_setup.path_saved_figures, \"toy_F1_comparison_DA_vs_no_DA.pdf\")\n",
    ")\n",
    "\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy_true_test, yy_pred_P_test_Fully_Supervised,\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    name_1=\"Fully_Supervised (Target)\",\n",
    "    name_2=\"DA\",\n",
    "    y_max_Delta_F1=1.0,\n",
    "    y_min_Delta_F1=-1.0,\n",
    "    f1_save_path=os.path.join(global_setup.path_saved_figures, \"toy_F1_comparison_DA_vs_Fully_Supervised.pdf\")\n",
    ")\n",
    "\n",
    "comparisons = [\n",
    "    (yy_true_val_no_DA, yy_pred_P_val_no_DA, yy_true_test, yy_pred_P_test_no_DA, \"Target vs. Source (no-DA)\"),\n",
    "    (yy_true_test, yy_pred_P_test_Fully_Supervised, yy_true_test, yy_pred_P_test_DA,   \"DA vs Fully_Supervised (Target)\"),\n",
    "    (yy_true_test, yy_pred_P_test_no_DA, yy_true_test, yy_pred_P_test_DA,   \"DA vs no-DA (Target)\"),\n",
    "]\n",
    "fig, ax, deltas = evaluation_tools.plot_overall_deltaF1_grouped(\n",
    "    comparisons,\n",
    "    class_names=class_names,\n",
    "    colors=[\"crimson\", \"darkorange\", \"limegreen\"],  # extend as needed\n",
    "    title=None,\n",
    "    figsize=(8, 6),\n",
    "    legend_kwargs={\"loc\":\"upper left\", \"frameon\":True, \"fontsize\": 12},\n",
    "    save_dir=global_setup.path_saved_figures, save_format=\"pdf\", filename=\"toy_delta_F1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_radar = {\n",
    "    \"Fully-Supervised\": {\n",
    "        \"y_true\": yy_true_test_Fully_Supervised,\n",
    "        \"y_pred\": yy_pred_P_test_Fully_Supervised,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \":\", \"linewidth\": 2.0, \"color\": \"grey\",\n",
    "            \"marker\": \"X\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Fully-Supervised\"\n",
    "        }\n",
    "    },\n",
    "    \"Source no-DA\": {\n",
    "        \"y_true\": yy_true_val_no_DA,\n",
    "        \"y_pred\": yy_pred_P_val_no_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"--\", \"linewidth\": 2.0, \"color\": \"royalblue\",\n",
    "            \"marker\": \"s\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Source no-DA\"\n",
    "        }\n",
    "    },\n",
    "    \"Target no-DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_no_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"--\", \"linewidth\": 2.0, \"color\": \"firebrick\",\n",
    "            \"marker\": \"v\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Target no-DA\"\n",
    "        }\n",
    "    },\n",
    "    \"Target (Train) DA\": {\n",
    "        \"y_true\": yy_true_train_DA,\n",
    "        \"y_pred\": yy_pred_P_train_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-\", \"linewidth\": 2.0, \"color\": \"darkorange\",\n",
    "            \"marker\": \"^\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Target (Train) DA\"\n",
    "        }\n",
    "    },\n",
    "    \"Target DA\": {\n",
    "        \"y_true\": yy_true_test,\n",
    "        \"y_pred\": yy_pred_P_test_DA,\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-\", \"linewidth\": 2.0, \"color\": \"green\",\n",
    "            \"marker\": \"o\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Target DA\"\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "fig, ax = evaluation_tools.radar_plot(\n",
    "    dict_radar=dict_radar, class_names=class_names,\n",
    "    title=\"F1 Radar Plot\", figsize=(8, 8), theta_offset=np.pi / 2, # first axis at 12 o'clock\n",
    "    r_ticks=(0.1, 0.3, 0.5, 0.7, 0.9), r_lim=(0.0, 1.0),\n",
    "    tick_labelsize=16, radial_labelsize=12, show_legend=True,\n",
    "    legend_kwargs={\n",
    "        \"loc\": \"upper left\", \"bbox_to_anchor\": (0.73, 1.0), \"fontsize\": 14, \"ncol\": 1,\n",
    "        \"title\": \"Evaluation Cases\", \"frameon\": True, \"fancybox\": True, \"shadow\": True, \"borderaxespad\": 0.0,\n",
    "    }\n",
    ")\n",
    "fig.savefig(os.path.join(global_setup.path_saved_figures, \"toy_F1_radar.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "    \"latents_no_DA_Source\": features_val_no_DA,\n",
    "    \"latents_no_DA_Target\": features_test_no_DA,\n",
    "    \"latents_DA_Target\": features_test_DA\n",
    "}\n",
    "\n",
    "latents_tSNE = evaluation_tools.tsne_per_key(\n",
    "    feat_dict,\n",
    "    standardize=False,\n",
    "    subsample=None,\n",
    "    random_state=137,\n",
    "    tsne_kwargs={\"perplexity\": 100},\n",
    "    return_all_key=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-100, 100)\n",
    "ylim = (-100, 100)\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Source_tSNE'], y_val=yy_true_val_no_DA,\n",
    "    X_test=latents_tSNE['latents_no_DA_Target_tSNE'], y_test=yy_true_test,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Source vs Target\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=14, size_test=14, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=4000, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Source no-DA\",\n",
    "    legend_split_2=\"Target no-DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'], yy_pred_val_no_DA, # yy_true_val_no_DA\n",
    "    class_counts=dset_val_no_DA.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Source\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'],\n",
    "    title=\"Latents no-DA: Source\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'], yy_pred_test_no_DA, # yy_true_test\n",
    "    class_counts=dset_test.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents no-DA: Target\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'],\n",
    "    title=\"Latents no-DA: Target\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Target_tSNE'], y_val=yy_true_test,\n",
    "    X_test=latents_tSNE['latents_DA_Target_tSNE'], y_test=yy_true_test,\n",
    "    class_names=None,\n",
    "    title=\"Latents Target: no-DA vs DA\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=14, size_test=14, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=4000, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Target no-DA\",\n",
    "    legend_split_2=\"Target DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'], yy_pred_test_DA, # yy_true_test\n",
    "    class_counts=dset_test.class_counts,\n",
    "    class_names=None,\n",
    "    title=\"Latents DA: Target\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=1.0, scatter_alpha=1.0,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'],\n",
    "    title=\"Latents DA: Target\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256,\n",
    "    sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    mask_zero_support=True,\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\",\n",
    "    contour_linewidths=0.4,\n",
    "    contour_label_fontsize=7,\n",
    "    contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    random_subsample=None,\n",
    "    xlim=xlim,\n",
    "    ylim=ylim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
