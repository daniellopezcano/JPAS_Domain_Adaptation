{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import wrapper_data_loaders\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "from JPAS_DA.wrapper_wandb import wrapper_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib inline\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_no_DA = \"09_no_DA\"\n",
    "path_load_DA = \"09_DA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_encoder_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(global_setup.path_models, path_load_no_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(global_setup.path_models, path_load_no_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "\n",
    "_, model_encoder_DA = save_load_tools.load_model_from_checkpoint(os.path.join(global_setup.path_models, path_load_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_DA = save_load_tools.load_model_from_checkpoint(os.path.join(global_setup.path_models, path_load_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "\n",
    "_ = evaluation_tools.compare_model_parameters(model_downstream_no_DA, model_downstream_DA, rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, config_no_DA = wrapper_tools.load_and_massage_config_file(os.path.join(global_setup.path_models, path_load_no_DA, \"config.yaml\"), path_load_no_DA)\n",
    "_, config_DA = wrapper_tools.load_and_massage_config_file(os.path.join(global_setup.path_models, path_load_DA, \"config.yaml\"), path_load_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = config_DA[\"data\"]\n",
    "\n",
    "# Extract configuration sub-dictionaries\n",
    "data_paths             = dict_data['data_paths']\n",
    "clean_opts             = dict_data['dict_clean_data_options']\n",
    "split_opts             = dict_data['dict_split_data_options']\n",
    "feature_opts           = dict_data['features_labels_options']\n",
    "provided_normalization = dict_data.get('provided_normalization', None)\n",
    "\n",
    "logging.info(\"ðŸ”§ Launching wrapper_data_loaders with loaded configuration...\")\n",
    "dset_loaders = wrapper_data_loaders.wrapper_data_loaders(\n",
    "    root_path                   = data_paths['root_path'],\n",
    "    load_JPAS_data              = data_paths['load_JPAS_data'],\n",
    "    load_DESI_data              = data_paths['load_DESI_data'],\n",
    "    random_seed_load            = data_paths['random_seed_load'],\n",
    "\n",
    "    apply_masks                 = clean_opts['apply_masks'],\n",
    "    mask_indices                = clean_opts['mask_indices'],\n",
    "    magic_numbers               = clean_opts['magic_numbers'],\n",
    "    i_band_sn_threshold         = clean_opts['i_band_sn_threshold'],\n",
    "    magnitude_flux_key          = clean_opts['magnitude_flux_key'],\n",
    "    magnitude_threshold         = clean_opts['magnitude_threshold'],\n",
    "    z_lim_QSO_cut               = clean_opts['z_lim_QSO_cut'],\n",
    "\n",
    "    train_ratio_both            = split_opts['train_ratio_both'],\n",
    "    val_ratio_both              = split_opts['val_ratio_both'],\n",
    "    test_ratio_both             = split_opts['test_ratio_both'],\n",
    "    random_seed_split_both      = split_opts['random_seed_split_both'],\n",
    "\n",
    "    train_ratio_only_DESI       = split_opts['train_ratio_only_DESI'],\n",
    "    val_ratio_only_DESI         = split_opts['val_ratio_only_DESI'],\n",
    "    test_ratio_only_DESI        = split_opts['test_ratio_only_DESI'],\n",
    "    random_seed_split_only_DESI = split_opts['random_seed_split_only_DESI'],\n",
    "\n",
    "    define_dataset_loaders_keys = feature_opts['define_dataset_loaders_keys'],\n",
    "    keys_xx                     = feature_opts['keys_xx'],\n",
    "    keys_yy                     = feature_opts['keys_yy'],\n",
    "    normalization_source_key    = feature_opts['normalization_source_key'],\n",
    "    normalize                   = feature_opts['normalize'],\n",
    "\n",
    "    provided_normalization      = provided_normalization\n",
    ")\n",
    "\n",
    "dset_val_no_DA = dset_loaders['DESI_only'][\"val\"]\n",
    "dset_val_DA = dset_loaders['JPAS_matched'][\"val\"]\n",
    "dset_test = dset_loaders['JPAS_matched'][\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy_true = dset_val_no_DA(batch_size=dset_val_no_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_no_DA = yy_true.cpu().numpy()\n",
    "features_val_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_no_DA = np.argmax(yy_pred_P_val_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_DA(batch_size=dset_val_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_val_DA = yy_true.cpu().numpy()\n",
    "features_val_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_DA = np.argmax(yy_pred_P_val_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_no_DA = np.argmax(yy_pred_P_test_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_DA = np.argmax(yy_pred_P_test_DA, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset_test.xx.keys())\n",
    "print(dset_test.xx['OBS'].shape)\n",
    "print(dset_test.xx['MORPHTYPE_int'].shape)\n",
    "\n",
    "print(len(dset_test.means))\n",
    "print(dset_test.means[0].shape)\n",
    "print(dset_test.means[-1].shape)\n",
    "\n",
    "print(xx.shape)\n",
    "print(yy_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(dset_test.class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_val_no_DA, yy_pred_P_val_no_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"val no DA\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"test no DA\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_val_DA, yy_pred_P_val_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"val DA\"\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"test DA\"\n",
    ")\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_no_DA,\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='TPR Comparison: DA vs no DA',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=global_setup.class_names,\n",
    "    name_1=\"no DA\",\n",
    "    name_2=\"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # === Stack all feature representations together ===\n",
    "# n_val_no_DA = features_val_no_DA.shape[0]\n",
    "# n_val_DA = features_val_DA.shape[0]\n",
    "# n_test_no_DA = features_test_no_DA.shape[0]\n",
    "# n_test_DA = features_test_DA.shape[0]\n",
    "\n",
    "# X_all = np.vstack([\n",
    "#     features_val_no_DA,\n",
    "#     features_val_DA,\n",
    "#     features_test_no_DA,\n",
    "#     features_test_DA\n",
    "# ])\n",
    "\n",
    "# # === Perform shared t-SNE projection ===\n",
    "# tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "# X_all_tsne = tsne.fit_transform(X_all)\n",
    "\n",
    "# # === Split back to original domains ===\n",
    "# i0 = 0\n",
    "# i1 = i0 + n_val_no_DA\n",
    "# i2 = i1 + n_val_DA\n",
    "# i3 = i2 + n_test_no_DA\n",
    "# i4 = i3 + n_test_DA\n",
    "\n",
    "# X_val_no_DA_tsne   = X_all_tsne[i0:i1]\n",
    "# X_val_DA_tsne      = X_all_tsne[i1:i2]\n",
    "# X_test_no_DA_tsne  = X_all_tsne[i2:i3]\n",
    "# X_test_DA_tsne     = X_all_tsne[i3:i4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_tools.plot_tsne_comparison_single_pair(\n",
    "#     X_val_no_DA_tsne, yy_true_val_no_DA,\n",
    "#     X_test_no_DA_tsne, yy_true_test,\n",
    "#     dset_test.class_counts,\n",
    "#     class_names=global_setup.class_names,\n",
    "#     title_set1=\"No DA - Validation\",\n",
    "#     title_set2=\"No DA - Test\",\n",
    "#     n_bins=128,\n",
    "#     sigma=2.0,\n",
    "#     scatter_size=1,\n",
    "#     scatter_alpha=1.0\n",
    "# )\n",
    "\n",
    "# evaluation_tools.plot_tsne_comparison_single_pair(\n",
    "#     X_val_DA_tsne, yy_true_val_DA,\n",
    "#     X_test_DA_tsne, yy_true_test,\n",
    "#     dset_test.class_counts,\n",
    "#     class_names=global_setup.class_names,\n",
    "#     title_set1=\"DA - Validation\",\n",
    "#     title_set2=\"DA - Test\",\n",
    "#     n_bins=128,\n",
    "#     sigma=2.0,\n",
    "#     scatter_size=1,\n",
    "#     scatter_alpha=1.0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
