{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import wrapper_data_loaders\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "from JPAS_DA.wrapper_wandb import wrapper_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib inline\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = global_setup.class_names\n",
    "# class_names = [\"QSO_high\", \"no_QSO_high\"]\n",
    "\n",
    "n_classes = len(class_names)\n",
    "\n",
    "return_keys=['val_DESI_only', 'test_JPAS_matched']\n",
    "define_dataset_loaders_keys=['DESI_only', 'JPAS_matched']\n",
    "keys_yy=[\"SPECTYPE_int\", \"TARGETID\", \"DESI_FLUX_R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_no_DA = evaluation_tools.evaluate_results_from_load_paths(\n",
    "    paths_load=[\n",
    "        os.path.join(global_setup.path_models, \"09_no_DA\")\n",
    "    ],\n",
    "    return_keys=return_keys,\n",
    "    define_dataset_loaders_keys=define_dataset_loaders_keys,\n",
    "    keys_yy=keys_yy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DA = evaluation_tools.evaluate_results_from_load_paths(\n",
    "    paths_load=[\n",
    "        os.path.join(global_setup.path_models, \"09_DA\")\n",
    "    ],\n",
    "    return_keys=return_keys,\n",
    "    define_dataset_loaders_keys=define_dataset_loaders_keys,\n",
    "    keys_yy=keys_yy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_idx, model_outputs in RESULTS_no_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        yy_true = result[\"true\"]\n",
    "        yy_pred = result[\"prob\"]\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluation_tools.plot_confusion_matrix(\n",
    "            yy_true,\n",
    "            yy_pred,\n",
    "            class_names=class_names,\n",
    "            cmap=plt.cm.RdYlGn,\n",
    "            title=f\"{key.replace('_', ' ')} (no-DA Model {model_idx})\"\n",
    "        )\n",
    "\n",
    "for model_idx, model_outputs in RESULTS_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        yy_true = result[\"true\"]\n",
    "        yy_pred = result[\"prob\"]\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluation_tools.plot_confusion_matrix(\n",
    "            yy_true,\n",
    "            yy_pred,\n",
    "            class_names=class_names,\n",
    "            cmap=plt.cm.RdYlGn,\n",
    "            title=f\"{key.replace('_', ' ')} (DA Model {model_idx})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_model = 0\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['true'],\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['prob'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='no-DA model: JPAS test VS DESI-mocks test',\n",
    "    name_1 = \"DESI-mocks\",\n",
    "    name_2 = \"JPAS-obs\",\n",
    ")\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='JPAS test: DA VS no-DA',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['true'], RESULTS_no_DA[ii_model]['val_DESI_only']['prob'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    name_1=\"DESI-mocks\",\n",
    "    name_2=\"JPAS-obs\"\n",
    ")\n",
    "\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    name_1=\"no DA\",\n",
    "    name_2=\"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # === Stack all feature representations together ===\n",
    "# n_val_no_DA = features_val_no_DA.shape[0]\n",
    "# n_val_DA = features_val_DA.shape[0]\n",
    "# n_test_no_DA = features_test_no_DA.shape[0]\n",
    "# n_test_DA = features_test_DA.shape[0]\n",
    "\n",
    "# X_all = np.vstack([\n",
    "#     features_val_no_DA,\n",
    "#     features_val_DA,\n",
    "#     features_test_no_DA,\n",
    "#     features_test_DA\n",
    "# ])\n",
    "\n",
    "# # === Perform shared t-SNE projection ===\n",
    "# tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "# X_all_tsne = tsne.fit_transform(X_all)\n",
    "\n",
    "# # === Split back to original domains ===\n",
    "# i0 = 0\n",
    "# i1 = i0 + n_val_no_DA\n",
    "# i2 = i1 + n_val_DA\n",
    "# i3 = i2 + n_test_no_DA\n",
    "# i4 = i3 + n_test_DA\n",
    "\n",
    "# X_val_no_DA_tsne   = X_all_tsne[i0:i1]\n",
    "# X_val_DA_tsne      = X_all_tsne[i1:i2]\n",
    "# X_test_no_DA_tsne  = X_all_tsne[i2:i3]\n",
    "# X_test_DA_tsne     = X_all_tsne[i3:i4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_tools.plot_tsne_comparison_single_pair(\n",
    "#     X_val_no_DA_tsne, yy_true_val_no_DA,\n",
    "#     X_test_no_DA_tsne, yy_true_test,\n",
    "#     dset_test.class_counts,\n",
    "#     class_names=global_setup.class_names,\n",
    "#     title_set1=\"No DA - Validation\",\n",
    "#     title_set2=\"No DA - Test\",\n",
    "#     n_bins=128,\n",
    "#     sigma=2.0,\n",
    "#     scatter_size=1,\n",
    "#     scatter_alpha=1.0\n",
    "# )\n",
    "\n",
    "# evaluation_tools.plot_tsne_comparison_single_pair(\n",
    "#     X_val_DA_tsne, yy_true_val_DA,\n",
    "#     X_test_DA_tsne, yy_true_test,\n",
    "#     dset_test.class_counts,\n",
    "#     class_names=global_setup.class_names,\n",
    "#     title_set1=\"DA - Validation\",\n",
    "#     title_set2=\"DA - Test\",\n",
    "#     n_bins=128,\n",
    "#     sigma=2.0,\n",
    "#     scatter_size=1,\n",
    "#     scatter_alpha=1.0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_key=\"DESI_FLUX_R\"\n",
    "mag_bin_edges=(17, 19, 21, 22, 22.5)\n",
    "output_key=\"MAG_BIN_ID\"\n",
    "\n",
    "magnitude_ranges = [(mag_bin_edges[i], mag_bin_edges[i+1]) for i in range(len(mag_bin_edges)-1)]\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "colormaps = [plt.cm.Blues, plt.cm.Greens, plt.cm.YlOrBr, plt.cm.Reds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_no_DA = evaluation_tools.add_magnitude_bins_to_results(\n",
    "    RESULTS_no_DA, magnitude_key=magnitude_key, mag_bin_edges=mag_bin_edges, output_key=output_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DA = evaluation_tools.add_magnitude_bins_to_results(\n",
    "    RESULTS_DA, magnitude_key=magnitude_key, mag_bin_edges=mag_bin_edges, output_key=output_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_val_DESI = -2.5 * np.log10(RESULTS_no_DA[ii_model]['val_DESI_only']['DESI_FLUX_R']) + 22.5\n",
    "\n",
    "masks_all = plotting_utils.plot_histogram_with_ranges_multiple(\n",
    "    magnitudes_val_DESI, ranges=magnitude_ranges, colors=colors, bins=42,\n",
    "    x_label=\"DESI Magnitude (R)\",\n",
    "    title=\"DESI R-band Magnitudes by Dataset Split and Loader\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = [f\"{lo}–{hi}\" for lo, hi in magnitude_ranges]\n",
    "num_bins = len(magnitude_ranges)\n",
    "\n",
    "# Sweep no-DA models\n",
    "for model_idx, model_outputs in RESULTS_no_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        mag_bins = result[\"MAG_BIN_ID\"]\n",
    "        yy_true_all = result[\"true\"]\n",
    "        yy_pred_all = result[\"prob\"]\n",
    "\n",
    "        for bin_id in range(num_bins):\n",
    "            mask = mag_bins == bin_id\n",
    "            if np.sum(mask) == 0:\n",
    "                continue  # Skip empty bins\n",
    "\n",
    "            yy_true = yy_true_all[mask]\n",
    "            yy_pred = yy_pred_all[mask]\n",
    "\n",
    "            evaluation_tools.plot_confusion_matrix(\n",
    "                yy_true,\n",
    "                yy_pred,\n",
    "                class_names=class_names,\n",
    "                cmap=colormaps[bin_id],\n",
    "                title=f\"{key.replace('_', ' ')} (no-DA {model_idx}) | Mag {bin_labels[bin_id]}\"\n",
    "            )\n",
    "\n",
    "# Sweep DA models\n",
    "for model_idx, model_outputs in RESULTS_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        mag_bins = result[\"MAG_BIN_ID\"]\n",
    "        yy_true_all = result[\"true\"]\n",
    "        yy_pred_all = result[\"prob\"]\n",
    "\n",
    "        for bin_id in range(num_bins):\n",
    "            mask = mag_bins == bin_id\n",
    "            if np.sum(mask) == 0:\n",
    "                continue  # Skip empty bins\n",
    "\n",
    "            yy_true = yy_true_all[mask]\n",
    "            yy_pred = yy_pred_all[mask]\n",
    "\n",
    "            evaluation_tools.plot_confusion_matrix(\n",
    "                yy_true,\n",
    "                yy_pred,\n",
    "                class_names=class_names,\n",
    "                cmap=colormaps[bin_id],\n",
    "                title=f\"{key.replace('_', ' ')} (DA {model_idx}) | Mag {bin_labels[bin_id]}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
