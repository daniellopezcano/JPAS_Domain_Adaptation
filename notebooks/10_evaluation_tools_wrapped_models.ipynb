{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import loading_tools\n",
    "from JPAS_DA.data import cleaning_tools\n",
    "from JPAS_DA.data import crossmatch_tools\n",
    "from JPAS_DA.data import process_dset_splits\n",
    "from JPAS_DA.data import data_loaders\n",
    "\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "from JPAS_DA.wrapper_wandb import wrapper_tools\n",
    "from JPAS_DA.evaluation import wandb_evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib widget\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweeps_direct_path_name = \"sweeps_direct\"\n",
    "sweeps_no_DA_path_name = \"sweeps_no_DA\"\n",
    "sweeps_DA_path_name = \"sweeps_DA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wandb_sweep_direct = os.path.join(global_setup.path_models, sweeps_direct_path_name)\n",
    "N_selected_sweeps_direct = 1\n",
    "sorted_list_sweep_names_direct, sorted_losses_direct = wandb_evaluation_tools.load_and_plot_sorted_sweeps(\n",
    "    path_wandb_sweep_direct, max_runs_to_plot=N_selected_sweeps_direct\n",
    ")\n",
    "path_wandb_sweep_no_DA = os.path.join(global_setup.path_models, sweeps_no_DA_path_name)\n",
    "N_selected_sweeps_no_DA = 1\n",
    "sorted_list_sweep_names_no_DA, sorted_losses_no_DA = wandb_evaluation_tools.load_and_plot_sorted_sweeps(\n",
    "    path_wandb_sweep_no_DA, max_runs_to_plot=N_selected_sweeps_no_DA\n",
    ")\n",
    "path_wandb_sweep_DA = os.path.join(global_setup.path_models, sweeps_DA_path_name)\n",
    "N_selected_sweeps_DA = 2\n",
    "sorted_list_sweep_names_DA, sorted_losses_DA = wandb_evaluation_tools.load_and_plot_sorted_sweeps(\n",
    "    path_wandb_sweep_DA, max_runs_to_plot=N_selected_sweeps_DA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_load_direct = [os.path.join(global_setup.path_models, sweeps_direct_path_name, sorted_list_sweep_names_direct[0])]\n",
    "logging.info(\"ðŸ” Validating model configs...\")\n",
    "configs_direct = []\n",
    "for path in paths_load_direct:\n",
    "    _, config = wrapper_tools.load_and_massage_config_file(\n",
    "        os.path.join(path, \"config.yaml\"), path\n",
    "    )\n",
    "    configs_direct.append(config)\n",
    "config_ref_no_DA = configs_direct[0]\n",
    "for i, cfg in enumerate(configs_direct[1:], 1):\n",
    "    logging.debug(f\"ðŸ” Comparing config 0 and config {i}\")\n",
    "    if not evaluation_tools.safe_compare(cfg['data'], config_ref_no_DA['data']):\n",
    "        raise ValueError(f\"ðŸš« Data config mismatch between model 0 and model {i}\")\n",
    "    \n",
    "\n",
    "paths_load_no_DA = [os.path.join(global_setup.path_models, sweeps_no_DA_path_name, sorted_list_sweep_names_no_DA[0])]\n",
    "logging.info(\"ðŸ” Validating model configs...\")\n",
    "configs_no_DA = []\n",
    "for path in paths_load_no_DA:\n",
    "    _, config = wrapper_tools.load_and_massage_config_file(\n",
    "        os.path.join(path, \"config.yaml\"), path\n",
    "    )\n",
    "    configs_no_DA.append(config)\n",
    "config_ref_no_DA = configs_no_DA[0]\n",
    "for i, cfg in enumerate(configs_no_DA[1:], 1):\n",
    "    logging.debug(f\"ðŸ” Comparing config 0 and config {i}\")\n",
    "    if not evaluation_tools.safe_compare(cfg['data'], config_ref_no_DA['data']):\n",
    "        raise ValueError(f\"ðŸš« Data config mismatch between model 0 and model {i}\")\n",
    "\n",
    "\n",
    "paths_load_DA = [os.path.join(global_setup.path_models, sweeps_DA_path_name, sorted_list_sweep_names_DA[0])]\n",
    "logging.info(\"ðŸ” Validating model configs...\")\n",
    "configs_DA = []\n",
    "for path in paths_load_DA:\n",
    "    _, config = wrapper_tools.load_and_massage_config_file(\n",
    "        os.path.join(path, \"config.yaml\"), path\n",
    "    )\n",
    "    configs_DA.append(config)\n",
    "config_ref_DA = configs_DA[0]\n",
    "for i, cfg in enumerate(configs_no_DA[1:], 1):\n",
    "    logging.debug(f\"ðŸ” Comparing config 0 and config {i}\")\n",
    "    if not evaluation_tools.safe_compare(cfg['data'], config_ref_DA['data']):\n",
    "        raise ValueError(f\"ðŸš« Data config mismatch between model 0 and model {i}\")\n",
    "\n",
    "\n",
    "config_data = config_ref_DA[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = global_setup.DATA_path\n",
    "load_JPAS_x_DESI_Raul   = global_setup.load_JPAS_x_DESI_Raul\n",
    "load_DESI_mocks_Raul    = global_setup.load_DESI_mocks_Raul\n",
    "load_Ignasi             = global_setup.load_Ignasi\n",
    "\n",
    "random_seed_load = global_setup.default_seed\n",
    "\n",
    "list_of_datasets_to_load = [\"JPAS_x_DESI_Raul\", \"DESI_mocks_Raul\", \"Ignasi\"]\n",
    "\n",
    "config_dict_cleaning = config_data['cleaning_config']\n",
    "\n",
    "dict_split_data_options = global_setup.dict_split_data_options\n",
    "\n",
    "keys_xx = config_data['keys_xx']\n",
    "keys_yy = [\"SPECTYPE_int\", \"TARGETID\", \"DESI_FLUX_R\"]\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = loading_tools.load_data_bundle(\n",
    "    root_path=root_path,\n",
    "    include=list_of_datasets_to_load,\n",
    "    JPAS_x_DESI_Raul={\"datasets\": load_JPAS_x_DESI_Raul},\n",
    "    DESI_mocks_Raul={\"datasets\": load_DESI_mocks_Raul},\n",
    "    Ignasi={\"datasets\": load_Ignasi},\n",
    "    random_seed=random_seed_load,\n",
    ")\n",
    "DATA = cleaning_tools.clean_data_pipeline(DATA, config=config_dict_cleaning, in_place=True)\n",
    "\n",
    "Dict_LoA = {\"intersection\": {}, \"outersection\": {}}\n",
    "\n",
    "IDs1, IDs2, IDs12, \\\n",
    "Dict_LoA[\"outersection\"][\"DESI_mocks_Raul\"], Dict_LoA[\"outersection\"][\"JPAS_x_DESI_Raul\"], \\\n",
    "Dict_LoA[\"intersection\"][\"DESI_mocks_Raul\"], Dict_LoA[\"intersection\"][\"JPAS_x_DESI_Raul\"] = crossmatch_tools.crossmatch_IDs_two_datasets(\n",
    "    DATA[\"DESI_mocks_Raul\"]['all_pd']['TARGETID'], DATA[\"JPAS_x_DESI_Raul\"]['all_pd']['TARGETID']\n",
    ")\n",
    "\n",
    "# Split the Lists of Arrays into training, validation, and testing sets\n",
    "Dict_LoA_split = {\"intersection\":{}, \"outersection\":{}}\n",
    "\n",
    "Dict_LoA_split[\"intersection\"][\"JPAS_x_DESI_Raul\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"intersection\"][\"JPAS_x_DESI_Raul\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_intersection\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_intersection\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_intersection\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_intersection\"]\n",
    ")\n",
    "Dict_LoA_split[\"outersection\"][\"DESI_mocks_Raul\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"outersection\"][\"DESI_mocks_Raul\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_outersection\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_outersection\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_outersection\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_outersection\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dsets = [\n",
    "    (\"DESI_mocks_Raul\", \"outersection\"),\n",
    "    (\"JPAS_x_DESI_Raul\", \"intersection\")\n",
    "]\n",
    "xx = {}\n",
    "yy = {}\n",
    "for key_dset, key_xmatch in extract_dsets:\n",
    "    xx[key_dset] = {}\n",
    "    yy[key_dset] = {}\n",
    "    for split in global_setup.splits:\n",
    "        LoA_ = Dict_LoA_split[key_xmatch][key_dset].get(split, [])\n",
    "        _, xx_, yy_ = process_dset_splits.extract_from_block_by_LoA(\n",
    "            block=DATA[key_dset], LoA=LoA_, keys_xx=keys_xx, keys_yy=keys_yy\n",
    "        )\n",
    "        xx_batch = data_loaders.stack_features_from_dict_flattened(xx_, np.arange(len(np.concatenate(LoA_))))\n",
    "        xx[key_dset][split] = torch.tensor(xx_batch, dtype=torch.float32, device=device)\n",
    "        yy[key_dset][split] = yy_\n",
    "\n",
    "\n",
    "key_dset = \"Ignasi\"\n",
    "split = \"all\"\n",
    "xx[key_dset] = {}\n",
    "yy[key_dset] = {}\n",
    "LoA_, xx_, yy_ = process_dset_splits.extract_from_block_by_LoA(\n",
    "    block=DATA[key_dset],\n",
    "    LoA=np.arange(DATA[\"Ignasi\"]['all_observations'].shape[0])[:, None].tolist(),\n",
    "    keys_xx=keys_xx,\n",
    "    keys_yy=keys_yy\n",
    ")\n",
    "xx_batch = data_loaders.stack_features_from_dict_flattened(xx_, np.arange(len(np.concatenate(LoA_))))\n",
    "xx[key_dset][split] = torch.tensor(xx_batch, dtype=torch.float32, device=device)\n",
    "yy[key_dset][split] = yy_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_encoder_direct = os.path.join(global_setup.path_models, paths_load_direct[0], \"model_encoder.pt\")\n",
    "assert os.path.isfile(path_load_encoder_direct), f\"âŒ Encoder checkpoint not found: {path_load_encoder_direct}\"\n",
    "logging.info(f\"ðŸ“¥ Loading encoder from checkpoint: {path_load_encoder_direct}\")\n",
    "_, model_encoder_direct = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_encoder_direct, model_building_tools.create_mlp\n",
    ")\n",
    "model_encoder_direct.eval()\n",
    "model_encoder_direct.to(device)\n",
    "\n",
    "path_load_downstream_direct = os.path.join(global_setup.path_models, paths_load_direct[0], \"model_downstream.pt\")\n",
    "assert os.path.isfile(path_load_downstream_direct), f\"âŒ Downstream checkpoint not found: {path_load_downstream_direct}\"\n",
    "logging.info(f\"ðŸ“¥ Loading downstream model from checkpoint: {path_load_downstream_direct}\")\n",
    "_, model_downstream_direct = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_downstream_direct, model_building_tools.create_mlp\n",
    ")\n",
    "model_downstream_direct.eval()\n",
    "model_downstream_direct.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_load_encoder_no_DA = os.path.join(global_setup.path_models, paths_load_no_DA[0], \"model_encoder.pt\")\n",
    "assert os.path.isfile(path_load_encoder_no_DA), f\"âŒ Encoder checkpoint not found: {path_load_encoder_no_DA}\"\n",
    "logging.info(f\"ðŸ“¥ Loading encoder from checkpoint: {path_load_encoder_no_DA}\")\n",
    "_, model_encoder_no_DA = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_encoder_no_DA, model_building_tools.create_mlp\n",
    ")\n",
    "model_encoder_no_DA.eval()\n",
    "model_encoder_no_DA.to(device)\n",
    "\n",
    "path_load_downstream_no_DA = os.path.join(global_setup.path_models, paths_load_no_DA[0], \"model_downstream.pt\")\n",
    "assert os.path.isfile(path_load_downstream_no_DA), f\"âŒ Downstream checkpoint not found: {path_load_downstream_no_DA}\"\n",
    "logging.info(f\"ðŸ“¥ Loading downstream model from checkpoint: {path_load_downstream_no_DA}\")\n",
    "_, model_downstream_no_DA = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_downstream_no_DA, model_building_tools.create_mlp\n",
    ")\n",
    "model_downstream_no_DA.eval()\n",
    "model_downstream_no_DA.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_load_encoder_DA = os.path.join(global_setup.path_models, paths_load_DA[0], \"model_encoder.pt\")\n",
    "assert os.path.isfile(path_load_encoder_DA), f\"âŒ Encoder checkpoint not found: {path_load_encoder_DA}\"\n",
    "logging.info(f\"ðŸ“¥ Loading encoder from checkpoint: {path_load_encoder_DA}\")\n",
    "_, model_encoder_DA = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_encoder_DA, model_building_tools.create_mlp, use_batchnorm = False\n",
    ")\n",
    "model_encoder_DA.eval()\n",
    "model_encoder_DA.to(device)\n",
    "\n",
    "path_load_downstream_DA = os.path.join(global_setup.path_models, paths_load_DA[0], \"model_downstream.pt\")\n",
    "assert os.path.isfile(path_load_downstream_DA), f\"âŒ Downstream checkpoint not found: {path_load_downstream_DA}\"\n",
    "logging.info(f\"ðŸ“¥ Loading downstream model from checkpoint: {path_load_downstream_DA}\")\n",
    "_, model_downstream_DA = save_load_tools.load_model_from_checkpoint(\n",
    "    path_load_downstream_DA, model_building_tools.create_mlp\n",
    ")\n",
    "model_downstream_DA.eval()\n",
    "model_downstream_DA.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dsets = [\n",
    "    (\"DESI_mocks_Raul\", \"outersection\"),\n",
    "    (\"JPAS_x_DESI_Raul\", \"intersection\")\n",
    "]\n",
    "features = {\"direct\" : {}, \"no-DA\" : {}, \"DA\" : {}}\n",
    "probs = {\"direct\" : {}, \"no-DA\" : {}, \"DA\" : {}}\n",
    "labels = {\"direct\" : {}, \"no-DA\" : {}, \"DA\" : {}}\n",
    "for key_dset, key_xmatch in extract_dsets:\n",
    "\n",
    "    features[\"direct\"][key_dset] = {}\n",
    "    probs[\"direct\"][key_dset] = {}\n",
    "    labels[\"direct\"][key_dset] = {}\n",
    "\n",
    "    features[\"no-DA\"][key_dset] = {}\n",
    "    probs[\"no-DA\"][key_dset] = {}\n",
    "    labels[\"no-DA\"][key_dset] = {}\n",
    "\n",
    "    features[\"DA\"][key_dset] = {}\n",
    "    probs[\"DA\"][key_dset] = {}\n",
    "    labels[\"DA\"][key_dset] = {}\n",
    "\n",
    "    for split in global_setup.splits:\n",
    "\n",
    "        xx_input = xx[key_dset][split]\n",
    "        with torch.no_grad():\n",
    "            features_ = model_encoder_direct(xx_input)\n",
    "            logits_ = model_downstream_direct(features_)\n",
    "            probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "        features[\"direct\"][key_dset][split] = features_.cpu().numpy()\n",
    "        probs[\"direct\"][key_dset][split] = probs_\n",
    "        labels[\"direct\"][key_dset][split] = np.argmax(probs_, axis=1)\n",
    "\n",
    "        xx_input = xx[key_dset][split]\n",
    "        with torch.no_grad():\n",
    "            features_ = model_encoder_no_DA(xx_input)\n",
    "            logits_ = model_downstream_no_DA(features_)\n",
    "            probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "        features[\"no-DA\"][key_dset][split] = features_.cpu().numpy()\n",
    "        probs[\"no-DA\"][key_dset][split] = probs_\n",
    "        labels[\"no-DA\"][key_dset][split] = np.argmax(probs_, axis=1)\n",
    "\n",
    "        xx_input = xx[key_dset][split]\n",
    "        with torch.no_grad():\n",
    "            features_ = model_encoder_DA(xx_input)\n",
    "            logits_ = model_downstream_DA(features_)\n",
    "            probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "        features[\"DA\"][key_dset][split] = features_.cpu().numpy()\n",
    "        probs[\"DA\"][key_dset][split] = probs_\n",
    "        labels[\"DA\"][key_dset][split] = np.argmax(probs_, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "key_dset = \"Ignasi\"\n",
    "split = \"all\"\n",
    "\n",
    "features[\"direct\"][key_dset] = {}\n",
    "probs[\"direct\"][key_dset] = {}\n",
    "labels[\"direct\"][key_dset] = {}\n",
    "\n",
    "features[\"no-DA\"][key_dset] = {}\n",
    "probs[\"no-DA\"][key_dset] = {}\n",
    "labels[\"no-DA\"][key_dset] = {}\n",
    "\n",
    "features[\"DA\"][key_dset] = {}\n",
    "probs[\"DA\"][key_dset] = {}\n",
    "labels[\"DA\"][key_dset] = {}\n",
    "\n",
    "\n",
    "xx_input = xx[key_dset][split]\n",
    "with torch.no_grad():\n",
    "    features_ = model_encoder_direct(xx_input)\n",
    "    logits_ = model_downstream_direct(features_)\n",
    "    probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "features[\"direct\"][key_dset][split] = features_.cpu().numpy()\n",
    "probs[\"direct\"][key_dset][split] = probs_\n",
    "labels[\"direct\"][key_dset][split] = np.argmax(probs_, axis=1)\n",
    "\n",
    "xx_input = xx[key_dset][split]\n",
    "with torch.no_grad():\n",
    "    features_ = model_encoder_no_DA(xx_input)\n",
    "    logits_ = model_downstream_no_DA(features_)\n",
    "    probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "features[\"no-DA\"][key_dset][split] = features_.cpu().numpy()\n",
    "probs[\"no-DA\"][key_dset][split] = probs_\n",
    "labels[\"no-DA\"][key_dset][split] = np.argmax(probs_, axis=1)\n",
    "\n",
    "xx_input = xx[key_dset][split]\n",
    "with torch.no_grad():\n",
    "    features_ = model_encoder_DA(xx_input)\n",
    "    logits_ = model_downstream_DA(features_)\n",
    "    probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "features[\"DA\"][key_dset][split] = features_.cpu().numpy()\n",
    "probs[\"DA\"][key_dset][split] = probs_\n",
    "labels[\"DA\"][key_dset][split] = np.argmax(probs_, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(global_setup.config_dict_cleaning[\"encoding\"][\"shared_mappings\"][\"SPECTYPE\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_radar = {\n",
    "    \"JPAS Obs. Fully_Supervised\": {\n",
    "        \"y_true\": yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "        \"y_pred\": probs[\"direct\"][\"DESI_mocks_Raul\"][\"test\"],\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-\", \"linewidth\": 1.0, \"color\": \"k\",\n",
    "            \"marker\": \"s\", \"markersize\": 10.0, \"fill_alpha\": 0.01,\n",
    "            \"label\": \"JPAS Obs. Fully_Supervised\"\n",
    "        }\n",
    "    },\n",
    "    \"Mocks no-DA\": {\n",
    "        \"y_true\": yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "        \"y_pred\": probs[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"],\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"--\", \"linewidth\": 2.0, \"color\": \"royalblue\",\n",
    "            \"marker\": \"^\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"Mocks no-DA\"\n",
    "        }\n",
    "    },\n",
    "    \"JPAS Obs. no-DA\": {\n",
    "        \"y_true\": yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "        \"y_pred\": probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-.\", \"linewidth\": 2.0, \"color\": \"crimson\",\n",
    "            \"marker\": \"X\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"JPAS Obs. no-DA\"\n",
    "        }\n",
    "    },\n",
    "    \"JPAS Obs. (Train) DA\": {\n",
    "        \"y_true\": yy[\"JPAS_x_DESI_Raul\"][\"train\"][\"SPECTYPE_int\"],\n",
    "        \"y_pred\": probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"train\"],\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \":\", \"linewidth\": 2.0, \"color\": \"orange\",\n",
    "            \"marker\": \"+\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"JPAS Obs. (Train) DA\"\n",
    "        }\n",
    "    },\n",
    "    \"JPAS Obs. DA\": {\n",
    "        \"y_true\": yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "        \"y_pred\": probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "        \"plot_kwargs\": {\n",
    "            \"linestyle\": \"-\", \"linewidth\": 2.0, \"color\": \"limegreen\",\n",
    "            \"marker\": \"o\", \"markersize\": 10.0, \"fill_alpha\": 0.05,\n",
    "            \"label\": \"JPAS Obs. DA\"\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"direct\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"JPAS Obs. (Fully_Supervised)\"\n",
    ")\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"Mocks (no-DA)\"\n",
    ")\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"JPAS Obs. (no-DA)\"\n",
    ")\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"train\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"train\"],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"JPAS Obs.-Train (DA)\"\n",
    ")\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn, title=\"JPAS Obs. (DA)\"\n",
    ")\n",
    "fig, ax = evaluation_tools.radar_plot(\n",
    "    dict_radar=dict_radar, class_names=class_names,\n",
    "    title=\"F1 Radar Plot\", figsize=(8, 8), theta_offset=np.pi / 2, # first axis at 12 o'clock\n",
    "    r_ticks=(0.1, 0.3, 0.5, 0.7, 0.9), r_lim=(0.0, 1.0),\n",
    "    tick_labelsize=16, radial_labelsize=12, show_legend=True,\n",
    "    legend_kwargs={\n",
    "        \"loc\": \"upper left\", \"bbox_to_anchor\": (0.73, 1.0), \"fontsize\": 9, \"ncol\": 1,\n",
    "        \"title\": \"Evaluation Cases\", \"frameon\": True, \"fancybox\": True, \"shadow\": True, \"borderaxespad\": 0.0,\n",
    "    },\n",
    ")\n",
    "fig.savefig(os.path.join(global_setup.path_saved_figures, \"F1_radar.pdf\"), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names, figsize=(10, 7),\n",
    "    cmap='seismic', title='TPR Comparison: DA vs no-DA', name_1 = \"no-DA\", name_2 = \"DA\"\n",
    ")\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"],\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names, name_1=\"Mocks\", name_2=\"no-DA: JPAS Obs.\",\n",
    "    y_max_Delta_F1=0.3, y_min_Delta_F1=-0.3, title_fontsize=20, color='k'\n",
    ")\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names, name_1=\"no-DA JPAS Obs.\", name_2=\"DA\",\n",
    "    y_max_Delta_F1=0.3, y_min_Delta_F1=-0.3, color='k'\n",
    ")\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"direct\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    class_names=class_names, name_1=\"Fully_Supervised JPAS Obs.\", name_2=\"DA\",\n",
    "    y_max_Delta_F1=0.3, y_min_Delta_F1=-0.3, color='k'\n",
    ")\n",
    "\n",
    "comparisons = [\n",
    "    (yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"], yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"], \"JPAS Obs. vs Mocks no-DA\"),\n",
    "    (yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"direct\"][\"JPAS_x_DESI_Raul\"][\"test\"], yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],   \"DA vs Fully_Supervised JPAS Obs.\"),\n",
    "    (yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"], yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"], probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],   \"DA vs no-DA JPAS Obs.\"),\n",
    "]\n",
    "fig, ax, deltas = evaluation_tools.plot_overall_deltaF1_grouped(\n",
    "    comparisons,\n",
    "    class_names=class_names,\n",
    "    colors=[\"crimson\", \"darkorange\", \"limegreen\"],  # extend as needed\n",
    "    title=None,\n",
    "    figsize=(8, 6),\n",
    "    legend_kwargs={\"loc\":\"upper right\", \"frameon\":True, \"fontsize\": 12},\n",
    "    save_dir=global_setup.path_saved_figures, save_format=\"pdf\", filename=\"delta_F1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Font & style config (same as before; tweak if desired) ----\n",
    "FS_TITLE = 24\n",
    "FS_LABEL = 20\n",
    "FS_TICKS = 18\n",
    "FS_CELL  = 14\n",
    "FS_CELL_DIAG = 14\n",
    "FS_CBAR_LABEL = 20\n",
    "FS_CBAR_TICKS = 16\n",
    "TICK_ROT = 20\n",
    "\n",
    "threshold_color = 0.5\n",
    "cmap = plt.cm.RdYlGn\n",
    "\n",
    "# ---- Cases: (title, y_true, y_pred_probs) ----\n",
    "cases = [\n",
    "    (\"Mocks (no-DA)\",\n",
    "     yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "     probs[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"]),\n",
    "\n",
    "    (\"JPAS Obs. (no-DA)\",\n",
    "     yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "     probs[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"]),\n",
    "\n",
    "    (\"JPAS Obs. (Fully_Supervised)\",\n",
    "     yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "     probs[\"direct\"][\"JPAS_x_DESI_Raul\"][\"test\"]),\n",
    "\n",
    "    (\"JPAS Obs. (DA)\",\n",
    "     yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "     probs[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"]),\n",
    "]\n",
    "\n",
    "# Classes & color normalization\n",
    "n_classes = len(class_names)\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "\n",
    "# ---- 2Ã—2 subpanels + thin colorbar column (compact layout) ----\n",
    "fig = plt.figure(figsize=(18, 16), constrained_layout=True, dpi=150)\n",
    "gs = fig.add_gridspec(\n",
    "    2, 3,\n",
    "    width_ratios=[1, 1, 0.05],  # thin colorbar on the right\n",
    "    height_ratios=[1, 1],\n",
    "    wspace=0.02, hspace=0.04\n",
    ")\n",
    "\n",
    "ax00 = fig.add_subplot(gs[0, 0])\n",
    "ax01 = fig.add_subplot(gs[0, 1], sharex=ax00, sharey=ax00)\n",
    "ax10 = fig.add_subplot(gs[1, 0], sharex=ax00, sharey=ax00)\n",
    "ax11 = fig.add_subplot(gs[1, 1], sharex=ax00, sharey=ax00)\n",
    "axes = np.array([[ax00, ax01], [ax10, ax11]])\n",
    "cax  = fig.add_subplot(gs[:, 2])\n",
    "\n",
    "# (optional) nudge constrained_layout pads a bit tighter\n",
    "fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.01, wspace=0.02, hspace=0.02)\n",
    "\n",
    "# Shared limits/ticks (reverse y to keep row 0 at the top with origin='upper')\n",
    "xlim = (-0.5, n_classes - 0.5)\n",
    "ylim = (n_classes - 0.5, -0.5)\n",
    "ticks = np.arange(n_classes)\n",
    "\n",
    "# Shared colorbar mappable\n",
    "mappable_for_cbar = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "mappable_for_cbar.set_array([])\n",
    "\n",
    "# ---- Draw panels ----\n",
    "for idx, (ax, (title, yy_true, yy_pred_P)) in enumerate(zip(axes.ravel(), cases)):\n",
    "    r, c = divmod(idx, 2)  # row, col in the 2Ã—2 grid\n",
    "\n",
    "    yy_true = np.asarray(yy_true).astype(int)\n",
    "    yy_pred = np.argmax(yy_pred_P, axis=1).astype(int)\n",
    "\n",
    "    # Confusion matrix including all classes\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    valid = (yy_true >= 0) & (yy_true < n_classes)\n",
    "    for t, p in zip(yy_true[valid], yy_pred[valid]):\n",
    "        if 0 <= t < n_classes and 0 <= p < n_classes:\n",
    "            cm[t, p] += 1\n",
    "\n",
    "    # Row-normalized proportions\n",
    "    row_sums = cm.sum(axis=1, keepdims=True)\n",
    "    cm_percent = np.divide(cm, row_sums, where=row_sums != 0)\n",
    "\n",
    "    # Heatmap\n",
    "    ax.imshow(cm_percent, interpolation='nearest', cmap=cmap, norm=norm, origin='upper')\n",
    "\n",
    "    # Shared axes styling\n",
    "    ax.set_xlim(xlim); ax.set_ylim(ylim)\n",
    "    ax.set_xticks(ticks); ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(class_names, fontsize=FS_TICKS)\n",
    "    ax.set_yticklabels(class_names, fontsize=FS_TICKS)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_title(title, fontsize=FS_TITLE, pad=20)\n",
    "\n",
    "    # Per-class metrics for diagonal annotation\n",
    "    precision = np.zeros(n_classes, dtype=float)\n",
    "    recall    = np.zeros(n_classes, dtype=float)\n",
    "    f1        = np.zeros(n_classes, dtype=float)\n",
    "    for i in range(n_classes):\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall[i]    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1[i]        = (2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "                        if (precision[i] + recall[i]) > 0 else 0.0)\n",
    "\n",
    "    # Cell annotations (counts + row-%; diagonal shows TPR/PPV/F1)\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            count   = cm[i, j]\n",
    "            percent = cm_percent[i, j] * 100 if row_sums[i, 0] != 0 else 0.0\n",
    "            text_color = \"white\" if cm_percent[i, j] > threshold_color else \"black\"\n",
    "\n",
    "            if i == j:\n",
    "                text = (f\"{count}\\n\"\n",
    "                        f\"TPR:{recall[i]*100:.1f}% \"\n",
    "                        f\"\\nPPV:{precision[i]*100:.1f}% \"\n",
    "                        f\"\\nF1:{f1[i]:.2f}\")\n",
    "                ax.text(j, i, text, ha=\"center\", va=\"center\",\n",
    "                        color=text_color, fontsize=FS_CELL_DIAG, fontweight='bold', linespacing=1.2)\n",
    "            else:\n",
    "                text = f\"{count}\\n{percent:.1f}%\"\n",
    "                ax.text(j, i, text, ha=\"center\", va=\"center\",\n",
    "                        color=text_color, fontsize=FS_CELL, linespacing=1.2)\n",
    "\n",
    "    # --- Outer-edge labels only (compact layout) ---\n",
    "    # Y-labels only on the left column\n",
    "    if c == 0:\n",
    "        ax.set_ylabel('True Label', fontsize=FS_LABEL, labelpad=6)\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # X-labels only on the bottom row\n",
    "    if r == 1:\n",
    "        ax.set_xlabel('Predicted Label', fontsize=FS_LABEL, labelpad=6)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=TICK_ROT, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    else:\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "# ---- Shared colorbar on the RIGHT ----\n",
    "cbar = fig.colorbar(mappable_for_cbar, cax=cax)\n",
    "cbar.set_label(\"True-label (row) normalized ratio\", fontsize=FS_CBAR_LABEL)\n",
    "cbar.ax.tick_params(labelsize=FS_CBAR_TICKS)\n",
    "cbar.set_ticks([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "# Save/show\n",
    "out_path = os.path.join(global_setup.path_saved_figures, \"confusion_matrices.pdf\")\n",
    "plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "    \"latents_no_DA_Source\": features[\"no-DA\"][\"DESI_mocks_Raul\"][\"test\"],\n",
    "    \"latents_no_DA_Target\": features[\"no-DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    \"latents_DA_Target\": features[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"]\n",
    "}\n",
    "\n",
    "latents_tSNE = evaluation_tools.tsne_per_key(\n",
    "    feat_dict,\n",
    "    standardize=False,\n",
    "    subsample=None,\n",
    "    random_state=137,\n",
    "    tsne_kwargs={\"perplexity\": 100},\n",
    "    return_all_key=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-150, 150)\n",
    "ylim = (-150, 150)\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Source_tSNE'], y_val=yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    X_test=latents_tSNE['latents_no_DA_Target_tSNE'], y_test=yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    class_names=class_names,\n",
    "    title=\"Latents no-DA: Source (Mocks) vs Target (JPAS x DESI obs.)\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=14, size_test=14, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=4000, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Source (Mocks) no-DA\",\n",
    "    legend_split_2=\"Target (JPAS x DESI obs.) no-DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'], yy[\"DESI_mocks_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"Latents no-DA: Source (Mocks)\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=0.003, scatter_alpha=0.3,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Source_tSNE'],\n",
    "    title=\"Latents no-DA: Source (Mocks)\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256, sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\", contour_linewidths=0.4, contour_label_fontsize=7, contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'], yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"Latents no-DA: Target (JPAS x DESI obs.)\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=0.1, scatter_alpha=0.5,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_no_DA_Target_tSNE'],\n",
    "    title=\"Latents no-DA: Target (JPAS x DESI obs.)\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256, sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\", contour_linewidths=0.4, contour_label_fontsize=7, contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_latents_scatter_val_test(\n",
    "    X_val=latents_tSNE['latents_no_DA_Target_tSNE'], y_val=yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    X_test=latents_tSNE['latents_DA_Target_tSNE'], y_test=yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    class_names=class_names,\n",
    "    title=\"Latents Target (JPAS x DESI obs.): no-DA vs DA\",\n",
    "    marker_val=\"o\", marker_test=\"^\",\n",
    "    size_val=8, size_test=8, alpha_val=0.7, alpha_test=0.7,\n",
    "    xlim=xlim, ylim=ylim,\n",
    "    subsample=None, seed=137,\n",
    "    edgecolor=None, linewidths=0.0,\n",
    "    legend_split_1=\"Target (JPAS x DESI obs.) no-DA\",\n",
    "    legend_split_2=\"Target (JPAS x DESI obs.) DA\"\n",
    ")\n",
    "evaluation_tools.plot_latents_scatter(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'], yy[\"JPAS_x_DESI_Raul\"][\"test\"][\"SPECTYPE_int\"],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"Latents DA: Target (JPAS x DESI obs.)\",\n",
    "    n_bins=128, sigma=2.0,\n",
    "    scatter_size=0.1, scatter_alpha=0.5,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_DA_Target_tSNE'],\n",
    "    title=\"Latents DA: Target (JPAS x DESI obs.)\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256, sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\", contour_linewidths=0.4, contour_label_fontsize=7, contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "    \"latents_DA_JPAS_x_DESI\": features[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"],\n",
    "    \"latents_DA_all_JPAS\": features[\"DA\"][\"Ignasi\"][\"all\"],\n",
    "}\n",
    "\n",
    "subsample = features[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"].shape[0]\n",
    "\n",
    "latents_tSNE = evaluation_tools.tsne_per_key(\n",
    "    feat_dict,\n",
    "    standardize=False,\n",
    "    subsample={\"latents_DA_JPAS_x_DESI\": subsample, \"latents_DA_all_JPAS\": subsample},\n",
    "    random_state=137,\n",
    "    tsne_kwargs={\"perplexity\": 100},\n",
    "    return_all_key=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (-100, 100)\n",
    "ylim = (-100, 100)\n",
    "\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_DA_JPAS_x_DESI_tSNE'],\n",
    "    title=\"Latents JPAS x DESI\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256, sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\", contour_linewidths=0.4, contour_label_fontsize=7, contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")\n",
    "evaluation_tools.plot_latent_density_2d(\n",
    "    latents_tSNE['latents_DA_all_JPAS_tSNE'],\n",
    "    title=\"Latents all JPAS\",\n",
    "    density_method=\"hist\", # or \"kde\"\n",
    "    bins=256, sigma=2.0, # ignored if density_method=\"kde\"\n",
    "    norm_mode=\"max\",\n",
    "    color_scale=\"linear\",\n",
    "    contour_fracs=(0.01, 0.1, 0.3, 0.6),\n",
    "    contour_colors=\"k\", contour_linewidths=0.4, contour_label_fontsize=7, contour_label_color=\"k\",\n",
    "    show_points=False,\n",
    "    points_alpha=0.1,\n",
    "    points_size=2,\n",
    "    xlim=xlim, ylim=ylim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, IDs, _, _, LoA_intersection_JPAS_x_DESI_Raul_test, LoA_intersection_Ignasi_all = crossmatch_tools.crossmatch_IDs_two_datasets(\n",
    "    yy['JPAS_x_DESI_Raul']['test']['TARGETID'], DATA['Ignasi']['all_pd']['TARGETID']\n",
    ")\n",
    "_, _, _, _, _, LoA_intersection_JPAS_x_DESI_Raul_DATA_test, _ = crossmatch_tools.crossmatch_IDs_two_datasets(\n",
    "    DATA['JPAS_x_DESI_Raul']['all_pd']['TARGETID'], IDs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€\n",
    "survey_jpas   = \"JPAS_x_DESI_Raul\"\n",
    "survey_ignasi = \"Ignasi\"\n",
    "NN_plot = 1000\n",
    "rng = np.random.default_rng(0)\n",
    "USE_LOG_Y = True\n",
    "\n",
    "# Filtering params\n",
    "RATIO_DEV_THR = 50.     # keep if max |ratio - 1| > this (ratio = log10(Ignasi)/log10(JPAS))\n",
    "MIN_VALID_PTS = 1        # require at least this many finite ratio points\n",
    "\n",
    "# ---- helpers to normalize index containers ----\n",
    "def iter_indices(x):\n",
    "    if x is None:\n",
    "        return\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        for v in x:\n",
    "            if v is None: \n",
    "                continue\n",
    "            yield int(v)\n",
    "    else:\n",
    "        yield int(x)\n",
    "\n",
    "def first_index(x):\n",
    "    for v in iter_indices(x):\n",
    "        return v\n",
    "    return None\n",
    "\n",
    "def compute_ratio_for_id(idx_ID):\n",
    "    \"\"\"Return ratio array (or None) for first occurrence in each survey.\"\"\"\n",
    "    occ_jpas   = LoA_intersection_JPAS_x_DESI_Raul_DATA_test[idx_ID]\n",
    "    occ_ignasi = LoA_intersection_Ignasi_all[idx_ID]\n",
    "    i_j = first_index(occ_jpas)\n",
    "    i_i = first_index(occ_ignasi)\n",
    "    if i_j is None or i_i is None:\n",
    "        return None\n",
    "\n",
    "    obs_j = np.asarray(DATA[survey_jpas]['all_observations'][i_j], dtype=float)\n",
    "    obs_i = np.asarray(DATA[survey_ignasi]['all_observations'][i_i], dtype=float)\n",
    "\n",
    "    j_safe = np.log10(np.clip(obs_j, 1e-12, None))\n",
    "    i_safe = np.log10(np.clip(obs_i, 1e-12, None))\n",
    "    denom  = np.where(j_safe == 0, np.nan, j_safe)\n",
    "    ratio  = i_safe / denom\n",
    "    return ratio\n",
    "\n",
    "def id_passes_threshold(idx_ID, thr=RATIO_DEV_THR):\n",
    "    ratio = compute_ratio_for_id(idx_ID)\n",
    "    if ratio is None:\n",
    "        return False\n",
    "    valid = np.isfinite(ratio)\n",
    "    if valid.sum() < MIN_VALID_PTS:\n",
    "        return False\n",
    "    max_dev = np.nanmax(np.abs(ratio[valid] - 1.0))\n",
    "    return bool(max_dev > thr)\n",
    "\n",
    "# â”€â”€â”€â”€â”€ sampling â”€â”€â”€â”€â”€\n",
    "assert len(IDs) == len(LoA_intersection_JPAS_x_DESI_Raul_DATA_test) == len(LoA_intersection_Ignasi_all), \\\n",
    "    \"Lengths of IDs and intersection lookups must match.\"\n",
    "\n",
    "NN_eff = min(NN_plot, len(IDs))\n",
    "sample_all = rng.choice(len(IDs), NN_eff, replace=False)\n",
    "\n",
    "# Filter by threshold\n",
    "filtered_idxs = [idx for idx in sample_all if id_passes_threshold(idx)]\n",
    "if not filtered_idxs:\n",
    "    print(f\"â„¹ï¸ No IDs exceeded threshold (|ratio-1| > {RATIO_DEV_THR}). Nothing to plot.\")\n",
    "    filtered_idxs = []  # keep empty; the rest will no-op\n",
    "\n",
    "# colors/linestyles\n",
    "colors = plt.cm.plasma(np.linspace(0.08, 0.92, max(1, len(filtered_idxs))))\n",
    "linestyles = {survey_jpas: \"--\", survey_ignasi: \"-\"}\n",
    "\n",
    "# figure (main + ratio)\n",
    "fig, (ax, ax_ratio) = plt.subplots(\n",
    "    2, 1, figsize=(9, 8), height_ratios=[3, 1], sharex=True, gridspec_kw={'hspace': 0.06}\n",
    ")\n",
    "ax.set_ylabel(r'Flux [arb. units]', fontsize=18)\n",
    "ax_ratio.set_xlabel(r'$\\mathrm{Filter~Index}$', fontsize=18)\n",
    "ax_ratio.set_ylabel(r'$\\log_{10}(\\mathrm{Ignasi}) / \\log_{10}(\\mathrm{JPAS})$', fontsize=13)\n",
    "\n",
    "# legends scaffolding\n",
    "survey_handles = [\n",
    "    mpl.lines.Line2D([0], [0], color=\"gray\", linestyle=linestyles[survey_jpas], lw=2, label=\"JPASÃ—DESI\"),\n",
    "    mpl.lines.Line2D([0], [0], color=\"gray\", linestyle=linestyles[survey_ignasi], lw=2, label=\"Ignasi\"),\n",
    "]\n",
    "id_handles = []\n",
    "\n",
    "# â”€â”€â”€â”€â”€ plotting â”€â”€â”€â”€â”€\n",
    "for j, idx_ID in enumerate(filtered_idxs):\n",
    "    color = colors[j]\n",
    "    tid_label = str(IDs[idx_ID])\n",
    "    id_handles.append(mpl.lines.Line2D([0], [0], color=color, lw=3, label=f\"ID {tid_label}\"))\n",
    "\n",
    "    # occurrences\n",
    "    occ_jpas   = LoA_intersection_JPAS_x_DESI_Raul_DATA_test[idx_ID]\n",
    "    occ_ignasi = LoA_intersection_Ignasi_all[idx_ID]\n",
    "\n",
    "    # JPAS: plot every occurrence\n",
    "    for ii in iter_indices(occ_jpas):\n",
    "        obs = np.asarray(DATA[survey_jpas]['all_observations'][ii], dtype=float)\n",
    "        x = np.arange(obs.size)\n",
    "        ax.plot(x, obs, linestyle=linestyles[survey_jpas], lw=2.0, marker='o', ms=3.0,\n",
    "                color=color, alpha=0.9)\n",
    "\n",
    "    # Ignasi: plot every occurrence\n",
    "    for ii in iter_indices(occ_ignasi):\n",
    "        obs = np.asarray(DATA[survey_ignasi]['all_observations'][ii], dtype=float)\n",
    "        x = np.arange(obs.size)\n",
    "        ax.plot(x, obs, linestyle=linestyles[survey_ignasi], lw=2.0, marker='o', ms=3.0,\n",
    "                color=color, alpha=0.9)\n",
    "\n",
    "    # ratio: first occurrence each (already validated by filter)\n",
    "    ratio = compute_ratio_for_id(idx_ID)\n",
    "    if ratio is not None:\n",
    "        ax_ratio.plot(np.arange(ratio.size), ratio, color=color, lw=1.8, alpha=0.95)\n",
    "\n",
    "# â”€â”€â”€â”€â”€ styling â”€â”€â”€â”€â”€\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax_ratio.axhline(1.0, ls='--', lw=1.0, color='black', alpha=0.6)\n",
    "ax_ratio.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "leg0 = ax.legend(handles=survey_handles, loc='upper left', fontsize=12,\n",
    "                 fancybox=True, shadow=True, title=\"Survey\", title_fontsize=13)\n",
    "ax.add_artist(leg0)\n",
    "\n",
    "if id_handles:\n",
    "    leg1 = ax.legend(handles=id_handles, loc='upper right', fontsize=11,\n",
    "                     fancybox=True, shadow=True, title=f\"Sampled IDs (>|ratio-1|>{RATIO_DEV_THR})\", title_fontsize=12)\n",
    "    ax.add_artist(leg1)\n",
    "\n",
    "if USE_LOG_Y:\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dict = {\n",
    "    \"latents_DA_Raul_test_x_Ignasi\": features[\"DA\"][\"JPAS_x_DESI_Raul\"][\"test\"][np.concatenate(LoA_intersection_JPAS_x_DESI_Raul_test)],\n",
    "    \"latents_DA_Ignasi_x_Raul_test\": features[\"DA\"][\"Ignasi\"][\"all\"][np.concatenate(LoA_intersection_Ignasi_all)],\n",
    "}\n",
    "latents_tSNE = evaluation_tools.tsne_per_key(\n",
    "    feat_dict,\n",
    "    standardize=False,\n",
    "    subsample=None,\n",
    "    random_state=137,\n",
    "    tsne_kwargs={\"perplexity\": 100},\n",
    "    return_all_key=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = latents_tSNE['latents_DA_Raul_test_x_Ignasi_tSNE']\n",
    "B = latents_tSNE['latents_DA_Ignasi_x_Raul_test_tSNE']\n",
    "\n",
    "plt.figure(figsize=(7.5, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    A[:, 0], A[:, 1],\n",
    "    s=14, marker='X', alpha=0.9, edgecolors='none', color='royalblue'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    B[:, 0], B[:, 1],\n",
    "    s=5, marker='o', alpha=0.4, edgecolors='none', color='crimson'\n",
    ")\n",
    "\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitude cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_key=\"DESI_FLUX_R\"\n",
    "mag_bin_edges=(17, 19, 21, 22, 22.5)\n",
    "output_key=\"MAG_BIN_ID\"\n",
    "\n",
    "magnitude_ranges = [(mag_bin_edges[i], mag_bin_edges[i+1]) for i in range(len(mag_bin_edges)-1)]\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "colormaps = [plt.cm.Blues, plt.cm.Greens, plt.cm.YlOrBr, plt.cm.Reds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_plot = {\n",
    "    (\"Mocks\", \"Test\"): -2.5 * np.log10(yy[\"DESI_mocks_Raul\"][\"test\"]['DESI_FLUX_R']) + 22.5,\n",
    "    (\"JPAS x DESI\", \"Train\"): -2.5 * np.log10(yy[\"JPAS_x_DESI_Raul\"][\"train\"]['DESI_FLUX_R']) + 22.5,\n",
    "    (\"JPAS x DESI\", \"Test\"): -2.5 * np.log10(yy[\"JPAS_x_DESI_Raul\"][\"test\"]['DESI_FLUX_R']) + 22.5\n",
    "}\n",
    "labels_plot = {\n",
    "    (\"Mocks\", \"Test\"): yy[\"DESI_mocks_Raul\"][\"test\"]['SPECTYPE_int'],         \n",
    "    (\"JPAS x DESI\", \"Train\"): yy[\"JPAS_x_DESI_Raul\"][\"train\"]['SPECTYPE_int'], \n",
    "    (\"JPAS x DESI\", \"Test\"): yy[\"JPAS_x_DESI_Raul\"][\"test\"]['SPECTYPE_int']\n",
    "}\n",
    "masks_magnitudes, stats_magnitudes = plotting_utils.plot_histogram_with_ranges_multiple(\n",
    "    magnitudes_plot, ranges=magnitude_ranges, colors=colors, bins=42,\n",
    "    x_label=\"DESI Magnitude (R)\", title=\"DESI R-band Magnitudes\",\n",
    "    labels_dict=labels_plot, class_names=class_names, pct_decimals=0,\n",
    "    annotate_mode='text', legend_fontsize=12\n",
    ")\n",
    "\n",
    "stats_magnitudes[(\"Mocks\", \"Test\")][\"plot_kwargs\"] = {\n",
    "    \"linestyle\": \"--\", \"marker\": \"+\", \"markersize\": 8.0,\n",
    "    \"label\": \"Source-Test (Mocks) no-DA\",\n",
    "}\n",
    "stats_magnitudes[(\"JPAS x DESI\", \"Test\")][\"plot_kwargs\"] = {\n",
    "    \"linestyle\": \"-.\", \"marker\": \"x\", \"markersize\": 8.0,\n",
    "    \"label\": \"Target-Test (JPAS x DESI) no-DA\",\n",
    "}\n",
    "stats_magnitudes[(\"JPAS x DESI\", \"Train\")][\"plot_kwargs\"] = {\n",
    "    \"linestyle\": \":\", \"marker\": \"^\", \"markersize\": 8.0,\n",
    "    \"label\": \"Target-Training (JPAS x DESI) DA\",\n",
    "}\n",
    "fig, ax = plotting_utils.plot_per_class_counts_together(\n",
    "    stats_magnitudes,\n",
    "    yscale=\"log\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Per-class counts vs. magnitude (all entries together)\",\n",
    "    title_fontsize=18,  # title size\n",
    "    class_legend_kwargs={\n",
    "        \"loc\": \"upper left\", \"bbox_to_anchor\": (0.0, 1.0),\n",
    "        \"fontsize\": 10, \"title\": \"Classes\", \"frameon\": True, \"fancybox\": True, \"shadow\": True\n",
    "    },\n",
    "    entry_legend_kwargs={\n",
    "        \"loc\": \"upper left\", \"bbox_to_anchor\": (0.65, 1.0),\n",
    "        \"fontsize\": 9, \"ncol\": 1, \"title\": \"Evaluation Cases\", \"frameon\": True, \"fancybox\": True, \"shadow\": True\n",
    "    },\n",
    "    legend_outside=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.evaluate_all_plots_by_mag_bins(\n",
    "    masks_magnitudes=masks_magnitudes,\n",
    "    yy=yy,\n",
    "    probs=probs,\n",
    "    class_names=class_names,\n",
    "    dict_radar_styles=dict_radar,   # only used to copy the linestyles/markers\n",
    "    radar_title_base=\"F1 Radar Plot\",\n",
    "    radar_kwargs={\n",
    "        \"figsize\": (8, 8),\n",
    "        \"theta_offset\": np.pi / 2,\n",
    "        \"r_ticks\": (0.1, 0.3, 0.5, 0.7, 0.9),\n",
    "        \"r_lim\": (0.0, 1.0),\n",
    "        \"tick_labelsize\": 16,\n",
    "        \"radial_labelsize\": 12,\n",
    "        \"show_legend\": True,\n",
    "        \"legend_kwargs\": {\n",
    "            \"loc\": \"upper left\", \"bbox_to_anchor\": (0.73, 1.0), \"fontsize\": 9, \"ncol\": 1,\n",
    "            \"title\": \"Evaluation Cases\", \"frameon\": True, \"fancybox\": True, \"shadow\": True, \"borderaxespad\": 0.0,\n",
    "        },\n",
    "        \"title_pad\": 20,\n",
    "    },\n",
    "    colors=colors,\n",
    "    colormaps=colormaps,\n",
    "    show=False,                 # don't pop up windows\n",
    "    save_dir=global_setup.path_saved_figures,  # <<-- save here\n",
    "    save_format=\"pdf\",\n",
    "    save_dpi=250,\n",
    "    close_after_save=True,      # free memory in large loops\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
