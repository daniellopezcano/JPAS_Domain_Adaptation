{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA import global_setup\n",
    "from JPAS_DA.data import loading_tools\n",
    "from JPAS_DA.data import cleaning_tools\n",
    "from JPAS_DA.data import crossmatch_tools\n",
    "from JPAS_DA.data import process_dset_splits\n",
    "from JPAS_DA.data import data_loaders\n",
    "\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "from JPAS_DA.wrapper_wandb import wrapper_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib widget\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_load = [os.path.join(global_setup.path_models, \"09_DA\")]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Load and validate data config across all paths\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "logging.info(\"üîç Validating model configs...\")\n",
    "configs = []\n",
    "for path in paths_load:\n",
    "    _, config = wrapper_tools.load_and_massage_config_file(\n",
    "        os.path.join(path, \"config.yaml\"), path\n",
    "    )\n",
    "    configs.append(config)\n",
    "\n",
    "config_ref = configs[0]\n",
    "for i, cfg in enumerate(configs[1:], 1):\n",
    "    logging.debug(f\"üîç Comparing config 0 and config {i}\")\n",
    "    if not evaluation_tools.safe_compare(cfg['data'], config_ref['data']):\n",
    "        raise ValueError(f\"üö´ Data config mismatch between model 0 and model {i}\")\n",
    "\n",
    "config_data = config_ref[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = global_setup.DATA_path\n",
    "load_JPAS_x_DESI_Raul   = global_setup.load_JPAS_x_DESI_Raul\n",
    "load_DESI_mocks_Raul    = global_setup.load_DESI_mocks_Raul\n",
    "load_Ignasi             = global_setup.load_Ignasi\n",
    "\n",
    "random_seed_load = global_setup.default_seed\n",
    "\n",
    "list_of_datasets_to_load = [\"JPAS_x_DESI_Raul\", \"DESI_mocks_Raul\", \"Ignasi\"]\n",
    "\n",
    "config_dict_cleaning = config_data['cleaning_config']\n",
    "\n",
    "dict_split_data_options = global_setup.dict_split_data_options\n",
    "\n",
    "keys_xx = config_data['keys_xx']\n",
    "keys_yy = [\"SPECTYPE_int\", \"TARGETID\", \"DESI_FLUX_R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = loading_tools.load_data_bundle(\n",
    "    root_path=root_path,\n",
    "    include=list_of_datasets_to_load,\n",
    "    JPAS_x_DESI_Raul={\"datasets\": load_JPAS_x_DESI_Raul},\n",
    "    DESI_mocks_Raul={\"datasets\": load_DESI_mocks_Raul},\n",
    "    Ignasi={\"datasets\": load_Ignasi},\n",
    "    random_seed=random_seed_load,\n",
    ")\n",
    "DATA = cleaning_tools.clean_data_pipeline(DATA, config=config_dict_cleaning, in_place=True)\n",
    "\n",
    "Dict_LoA = {\"intersection\": {}, \"outersection\": {}}\n",
    "\n",
    "IDs1, IDs2, IDs12, \\\n",
    "Dict_LoA[\"outersection\"][\"DESI_mocks_Raul\"], Dict_LoA[\"outersection\"][\"JPAS_x_DESI_Raul\"], \\\n",
    "Dict_LoA[\"intersection\"][\"DESI_mocks_Raul\"], Dict_LoA[\"intersection\"][\"JPAS_x_DESI_Raul\"] = crossmatch_tools.crossmatch_IDs_two_datasets(\n",
    "    DATA[\"DESI_mocks_Raul\"]['all_pd']['TARGETID'], DATA[\"JPAS_x_DESI_Raul\"]['all_pd']['TARGETID']\n",
    ")\n",
    "\n",
    "# Split the Lists of Arrays into training, validation, and testing sets\n",
    "Dict_LoA_split = {\"intersection\":{}, \"outersection\":{}}\n",
    "\n",
    "Dict_LoA_split[\"intersection\"][\"JPAS_x_DESI_Raul\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"intersection\"][\"JPAS_x_DESI_Raul\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_intersection\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_intersection\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_intersection\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_intersection\"]\n",
    ")\n",
    "Dict_LoA_split[\"outersection\"][\"DESI_mocks_Raul\"] = process_dset_splits.split_LoA(\n",
    "    Dict_LoA[\"outersection\"][\"DESI_mocks_Raul\"],\n",
    "    train_ratio = dict_split_data_options[\"train_ratio_outersection\"],\n",
    "    val_ratio = dict_split_data_options[\"val_ratio_outersection\"],\n",
    "    test_ratio = dict_split_data_options[\"test_ratio_outersection\"],\n",
    "    seed = dict_split_data_options[\"random_seed_split_outersection\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = {}\n",
    "yy = {}\n",
    "for key_dset_split in [\"train\", \"val\", \"test\"]:\n",
    "\n",
    "    xx[key_dset_split] = {}\n",
    "    yy[key_dset_split] = {}\n",
    "\n",
    "    key_dset = \"DESI_mocks_Raul\"\n",
    "    key_xmatch = \"outersection\"\n",
    "    LoA_, xx_, yy_ = process_dset_splits.extract_from_block_by_LoA(\n",
    "        block=DATA[key_dset],\n",
    "        LoA=Dict_LoA_split[key_xmatch][key_dset][key_dset_split],\n",
    "        keys_xx=keys_xx,\n",
    "        keys_yy=keys_yy\n",
    "    )\n",
    "    xx_batch = data_loaders.stack_features_from_dict_flattened(xx_, np.arange(len(np.concatenate(LoA_))))\n",
    "    xx[key_dset_split][key_dset] = torch.tensor(xx_batch, dtype=torch.float32, device=device)\n",
    "    yy[key_dset_split][key_dset] = yy_\n",
    "\n",
    "    key_dset = \"JPAS_x_DESI_Raul\"\n",
    "    key_xmatch = \"intersection\"\n",
    "    LoA_, xx_, yy_ = process_dset_splits.extract_from_block_by_LoA(\n",
    "        block=DATA[key_dset],\n",
    "        LoA=Dict_LoA_split[key_xmatch][key_dset][key_dset_split],\n",
    "        keys_xx=keys_xx,\n",
    "        keys_yy=keys_yy\n",
    "    )\n",
    "    xx_batch = data_loaders.stack_features_from_dict_flattened(xx_, np.arange(len(np.concatenate(LoA_))))\n",
    "    xx[key_dset_split][key_dset] = torch.tensor(xx_batch, dtype=torch.float32, device=device)\n",
    "    yy[key_dset_split][key_dset] = yy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dset = \"Ignasi\"\n",
    "\n",
    "xx[key_dset] = {}\n",
    "yy[key_dset] = {}\n",
    "\n",
    "LoA_, xx_, yy_ = process_dset_splits.extract_from_block_by_LoA(\n",
    "    block=DATA[key_dset],\n",
    "    LoA=np.arange(DATA[\"Ignasi\"]['all_observations'].shape[0])[:, None].tolist(),\n",
    "    keys_xx=keys_xx,\n",
    "    keys_yy=keys_yy\n",
    ")\n",
    "xx_batch = data_loaders.stack_features_from_dict_flattened(xx_, np.arange(len(np.concatenate(LoA_))))\n",
    "xx[key_dset] = torch.tensor(xx_batch, dtype=torch.float32, device=device)\n",
    "yy[key_dset] = yy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_encoder = save_load_tools.load_model_from_checkpoint(\n",
    "    os.path.join(path, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream = save_load_tools.load_model_from_checkpoint(\n",
    "    os.path.join(path, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "\n",
    "model_encoder.to(device)\n",
    "model_downstream.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "probs = {}\n",
    "labels = {}\n",
    "for key_dset_split in [\"train\", \"val\", \"test\"]:\n",
    "\n",
    "    features[key_dset_split] = {}\n",
    "    probs[key_dset_split] = {}\n",
    "    labels[key_dset_split] = {}\n",
    "\n",
    "    key_dset = \"DESI_mocks_Raul\"\n",
    "    xx_input = xx[key_dset_split][key_dset]\n",
    "    with torch.no_grad():\n",
    "        features_ = model_encoder(xx_input)\n",
    "        logits_ = model_downstream(features_)\n",
    "        probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "\n",
    "    features[key_dset_split][key_dset] = features_.cpu().numpy()\n",
    "    probs[key_dset_split][key_dset] = probs_\n",
    "    labels[key_dset_split][key_dset] = np.argmax(probs_, axis=1)\n",
    "\n",
    "    key_dset = \"JPAS_x_DESI_Raul\"\n",
    "    xx_input = xx[key_dset_split][key_dset]\n",
    "    with torch.no_grad():\n",
    "        features_ = model_encoder(xx_input)\n",
    "        logits_ = model_downstream(features_)\n",
    "        probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "\n",
    "    features[key_dset_split][key_dset] = features_.cpu().numpy()\n",
    "    probs[key_dset_split][key_dset] = probs_\n",
    "    labels[key_dset_split][key_dset] = np.argmax(probs_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dset = \"Ignasi\"\n",
    "\n",
    "xx_input = xx[key_dset]\n",
    "with torch.no_grad():\n",
    "    features_ = model_encoder(xx_input)\n",
    "    logits_ = model_downstream(features_)\n",
    "    probs_ = torch.nn.functional.softmax(logits_, dim=1).cpu().numpy()\n",
    "\n",
    "features[key_dset] = features_.cpu().numpy()\n",
    "probs[key_dset] = probs_\n",
    "labels[key_dset] = np.argmax(probs_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(global_setup.config_dict_cleaning['encoding']['shared_mappings']['SPECTYPE'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dset_split = \"test\"\n",
    "key_dset = \"JPAS_x_DESI_Raul\"\n",
    "\n",
    "evaluation_tools.plot_confusion_matrix(\n",
    "    yy[key_dset_split][key_dset][\"SPECTYPE_int\"],\n",
    "    probs[key_dset_split][key_dset],\n",
    "    class_names=class_names,\n",
    "    cmap=plt.cm.RdYlGn\n",
    ")\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    features[key_dset_split][key_dset],\n",
    "    yy[key_dset_split][key_dset][\"SPECTYPE_int\"],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"DA: \" + key_dset_split + \" - \" + key_dset + \" - True\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.5,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=(-8, 10),\n",
    "    ylim=(-18, 6)\n",
    ")\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    features[key_dset_split][key_dset],\n",
    "    labels[key_dset_split][key_dset],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"DA: \" + key_dset_split + \" - \" + key_dset + \" - Pred\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.5,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=(-8, 10),\n",
    "    ylim=(-18, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = yy[key_dset_split][key_dset][\"SPECTYPE_int\"]\n",
    "X_emb = features[key_dset_split][key_dset]\n",
    "\n",
    "xlim=(-8, 10)\n",
    "ylim=(-18, 6)\n",
    "scatter_size=0.1\n",
    "scatter_alpha=0.5\n",
    "title = \"DA: \" + key_dset_split + \" - \" + key_dset\n",
    "\n",
    "unique_classes = np.unique(y_labels)\n",
    "cmap = plt.cm.get_cmap(\"tab10\")\n",
    "class_color_dict = {cls: cmap(i) for i, cls in enumerate(unique_classes)}\n",
    "class_rgb = np.array([class_color_dict[cls][:3] for cls in unique_classes])\n",
    "\n",
    "class_counts = np.array([np.sum(y_labels == cls) for cls in unique_classes])\n",
    "\n",
    "inv_freq_weights = 1 / class_counts\n",
    "inv_freq_weights /= np.sum(inv_freq_weights)\n",
    "\n",
    "# Determine plot limits\n",
    "x_min = np.min(X_emb[:, 0]) if xlim is None else xlim[0]\n",
    "x_max = np.max(X_emb[:, 0]) if xlim is None else xlim[1]\n",
    "y_min = np.min(X_emb[:, 1]) if ylim is None else ylim[0]\n",
    "y_max = np.max(X_emb[:, 1]) if ylim is None else ylim[1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_title(title, fontsize=14)\n",
    "ax.set_xlabel(\"t-SNE 1\", fontsize=12)\n",
    "ax.set_ylabel(\"t-SNE 2\", fontsize=12)\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.tick_params(labelsize=10)\n",
    "\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    idx = y_labels == cls\n",
    "    if np.sum(idx) == 0:\n",
    "        continue\n",
    "    ax.scatter(X_emb[idx, 0], X_emb[idx, 1],\n",
    "                color=class_color_dict[cls], s=scatter_size, alpha=scatter_alpha)\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color=class_color_dict[cls], label=class_names[i] if class_names else f\"Class {cls}\")\n",
    "    for i, cls in enumerate(unique_classes)\n",
    "]\n",
    "ax.legend(handles=legend_elements, title=\"Class\", fontsize=10, title_fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dset = \"Ignasi\"\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    features[key_dset],\n",
    "    labels[key_dset],\n",
    "    class_counts=None,\n",
    "    class_names=class_names,\n",
    "    title=\"DA: \" + key_dset + \" - Pred\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.5,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=(-8, 10),\n",
    "    ylim=(-18, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = features[key_dset]\n",
    "y_labels = np.zeros_like(X_emb[:, 0])\n",
    "\n",
    "xlim=(-8, 10)\n",
    "ylim=(-18, 6)\n",
    "scatter_size=0.1\n",
    "scatter_alpha=0.1\n",
    "title = \"DA: \" + key_dset\n",
    "\n",
    "unique_classes = np.unique(y_labels)\n",
    "cmap = plt.cm.get_cmap(\"tab10\")\n",
    "class_color_dict = {cls: cmap(i) for i, cls in enumerate(unique_classes)}\n",
    "class_rgb = np.array([class_color_dict[cls][:3] for cls in unique_classes])\n",
    "\n",
    "class_counts = np.array([np.sum(y_labels == cls) for cls in unique_classes])\n",
    "\n",
    "inv_freq_weights = 1 / class_counts\n",
    "inv_freq_weights /= np.sum(inv_freq_weights)\n",
    "\n",
    "# Determine plot limits\n",
    "x_min = np.min(X_emb[:, 0]) if xlim is None else xlim[0]\n",
    "x_max = np.max(X_emb[:, 0]) if xlim is None else xlim[1]\n",
    "y_min = np.min(X_emb[:, 1]) if ylim is None else ylim[0]\n",
    "y_max = np.max(X_emb[:, 1]) if ylim is None else ylim[1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_title(title, fontsize=14)\n",
    "ax.set_xlabel(\"t-SNE 1\", fontsize=12)\n",
    "ax.set_ylabel(\"t-SNE 2\", fontsize=12)\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.tick_params(labelsize=10)\n",
    "\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    idx = y_labels == cls\n",
    "    if np.sum(idx) == 0:\n",
    "        continue\n",
    "    ax.scatter(X_emb[idx, 0], X_emb[idx, 1],\n",
    "                color=class_color_dict[cls], s=scatter_size, alpha=scatter_alpha)\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color=class_color_dict[cls], label=class_names[i] if class_names else f\"Class {cls}\")\n",
    "    for i, cls in enumerate(unique_classes)\n",
    "]\n",
    "ax.legend(handles=legend_elements, title=\"Class\", fontsize=10, title_fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_keys=['val_DESI_only', 'test_JPAS_matched']\n",
    "define_dataset_loaders_keys=['DESI_only', 'JPAS_matched']\n",
    "keys_yy=[\"SPECTYPE_int\", \"TARGETID\", \"DESI_FLUX_R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_no_DA = evaluation_tools.evaluate_results_from_load_paths(\n",
    "    paths_load=[\n",
    "        os.path.join(global_setup.path_models, \"wandb_no_DA_latent_2\", \"my-sweep-0\")\n",
    "    ],\n",
    "    return_keys=return_keys,\n",
    "    define_dataset_loaders_keys=define_dataset_loaders_keys,\n",
    "    keys_yy=keys_yy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DA = evaluation_tools.evaluate_results_from_load_paths(\n",
    "    paths_load=[\n",
    "        os.path.join(global_setup.path_models, \"wandb_DA_latent_2\", \"my-sweep-0\")\n",
    "    ],\n",
    "    return_keys=return_keys,\n",
    "    define_dataset_loaders_keys=define_dataset_loaders_keys,\n",
    "    keys_yy=keys_yy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(RESULTS_no_DA[0]['val_DESI_only']['label']))\n",
    "\n",
    "if n_classes == 2:\n",
    "    class_names = ['QSO_high', 'no_QSO_high']\n",
    "else:\n",
    "    class_names = global_setup.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_idx, model_outputs in RESULTS_no_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        yy_true = result[\"true\"]\n",
    "        yy_pred = result[\"prob\"]\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluation_tools.plot_confusion_matrix(\n",
    "            yy_true,\n",
    "            yy_pred,\n",
    "            class_names=class_names,\n",
    "            cmap=plt.cm.RdYlGn,\n",
    "            title=f\"{key.replace('_', ' ')} (no-DA Model {model_idx})\"\n",
    "        )\n",
    "\n",
    "for model_idx, model_outputs in RESULTS_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        yy_true = result[\"true\"]\n",
    "        yy_pred = result[\"prob\"]\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        evaluation_tools.plot_confusion_matrix(\n",
    "            yy_true,\n",
    "            yy_pred,\n",
    "            class_names=class_names,\n",
    "            cmap=plt.cm.RdYlGn,\n",
    "            title=f\"{key.replace('_', ' ')} (DA Model {model_idx})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_model = 0\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['true'],\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['prob'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='no-DA model: JPAS test VS DESI-mocks test',\n",
    "    name_1 = \"DESI-mocks\",\n",
    "    name_2 = \"JPAS-obs\",\n",
    ")\n",
    "\n",
    "evaluation_tools.compare_TPR_confusion_matrices(\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='JPAS test: DA VS no-DA',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    RESULTS_no_DA[ii_model]['val_DESI_only']['true'], RESULTS_no_DA[ii_model]['val_DESI_only']['prob'],\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    name_1=\"DESI-mocks\",\n",
    "    name_2=\"JPAS-obs\"\n",
    ")\n",
    "\n",
    "metrics = evaluation_tools.compare_sets_performance(\n",
    "    RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_no_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    RESULTS_DA[ii_model]['test_JPAS_matched']['true'], RESULTS_DA[ii_model]['test_JPAS_matched']['prob'],\n",
    "    class_names=class_names,\n",
    "    name_1=\"no DA\",\n",
    "    name_2=\"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_positions_no_DA_mocks = RESULTS_no_DA[0]['val_DESI_only']['features']\n",
    "true_no_DA_mocks = RESULTS_no_DA[0]['val_DESI_only']['true']\n",
    "labels_no_DA_mocks = RESULTS_no_DA[0]['val_DESI_only']['label']\n",
    "prob_no_DA_mocks = RESULTS_no_DA[0]['val_DESI_only']['prob']\n",
    "DESI_FLUX_R_no_DA_mocks = RESULTS_no_DA[0]['val_DESI_only']['DESI_FLUX_R']\n",
    "\n",
    "latent_positions_no_DA_obs = RESULTS_no_DA[0]['test_JPAS_matched']['features']\n",
    "true_no_DA_obs = RESULTS_no_DA[0]['test_JPAS_matched']['true']\n",
    "labels_no_DA_obs = RESULTS_no_DA[0]['test_JPAS_matched']['label']\n",
    "prob_no_DA_obs = RESULTS_no_DA[0]['test_JPAS_matched']['prob']\n",
    "DESI_FLUX_R_no_DA_mocks = RESULTS_no_DA[0]['test_JPAS_matched']['DESI_FLUX_R']\n",
    "\n",
    "latent_positions_DA_obs = RESULTS_DA[0]['test_JPAS_matched']['features']\n",
    "true_DA_obs = RESULTS_DA[0]['test_JPAS_matched']['true']\n",
    "labels_DA_obs = RESULTS_DA[0]['test_JPAS_matched']['label']\n",
    "prob_DA_obs = RESULTS_DA[0]['test_JPAS_matched']['prob']\n",
    "DESI_FLUX_R_DA_mocks = RESULTS_DA[0]['test_JPAS_matched']['DESI_FLUX_R']\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# === Stack all feature representations together ===\n",
    "n_val_no_DA = latent_positions_no_DA_mocks.shape[0]\n",
    "n_test_no_DA = latent_positions_no_DA_obs.shape[0]\n",
    "n_test_DA = latent_positions_DA_obs.shape[0]\n",
    "X_all = np.vstack([\n",
    "    latent_positions_no_DA_mocks,\n",
    "    latent_positions_no_DA_obs,\n",
    "    latent_positions_DA_obs\n",
    "])\n",
    "# === Perform shared t-SNE projection ===\n",
    "tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "X_all_tsne = tsne.fit_transform(X_all)\n",
    "# === Split back to original domains ===\n",
    "i0 = 0\n",
    "i1 = i0 + n_val_no_DA\n",
    "i2 = i1 + n_test_no_DA\n",
    "i3 = i2 + n_test_DA\n",
    "latent_positions_no_DA_mocks_tsne   = X_all_tsne[i0:i1]\n",
    "latent_positions_no_DA_obs_tsne  = X_all_tsne[i1:i2]\n",
    "latent_positions_DA_obs_tsne     = X_all_tsne[i2:i3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_no_DA_mocks_tsne, true_no_DA_mocks,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Mocks\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_no_DA_obs_tsne, true_no_DA_obs,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_DA_obs_tsne, true_DA_obs,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_no_DA_mocks_tsne, true_no_DA_mocks,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Mocks\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_no_DA_obs_tsne, true_no_DA_obs,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    latent_positions_DA_obs_tsne, true_DA_obs,\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_tools.plot_tsne_single(\n",
    "    X_val_no_DA_tsne, RESULTS_no_DA[ii_model]['val_DESI_only']['true'],\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Mocks\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    X_test_no_DA_tsne, RESULTS_no_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"No DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")\n",
    "\n",
    "evaluation_tools.plot_tsne_single(\n",
    "    X_test_DA_tsne, RESULTS_DA[ii_model]['test_JPAS_matched']['true'],\n",
    "    class_counts=None,\n",
    "    class_names=None,\n",
    "    title=\"DA - Data\",\n",
    "    n_bins=128,\n",
    "    sigma=2.0,\n",
    "    scatter_size=0.1,\n",
    "    scatter_alpha=0.1,\n",
    "    xlim=None,\n",
    "    ylim=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Colors and class names -------\n",
    "class_colors = {0: 'crimson', 1: 'limegreen', 2: 'royalblue', 3: 'yellow'}\n",
    "class_names = {0: 'Galaxy', 1: 'QSO high-z', 2: 'QSO low-z', 3: 'Star'}\n",
    "alpha = 0.5\n",
    "\n",
    "# ------- Datasets (title, features, true, pred, prob) -------\n",
    "datasets = [\n",
    "    (\"No-DA Mocks\", latent_positions_no_DA_mocks, true_no_DA_mocks, labels_no_DA_mocks, prob_no_DA_mocks),\n",
    "    (\"No-DA Data\", latent_positions_no_DA_obs, true_no_DA_obs, labels_no_DA_obs, prob_no_DA_obs),\n",
    "    (\"DA Data\", latent_positions_DA_obs, true_DA_obs, labels_DA_obs, prob_DA_obs),\n",
    "]\n",
    "\n",
    "# ------- Utility function to scale point size -------\n",
    "def compute_point_size(n_points, min_size=1, max_size=100, ref_points=30000):\n",
    "    \"\"\"Scale point size inversely with dataset size.\"\"\"\n",
    "    default_size = ref_points / n_points\n",
    "    return max(min_size, min(max_size, default_size))\n",
    "\n",
    "# ------- Utility plotting functions -------\n",
    "def scatter_by_class(ax, features, y, colors, point_size):\n",
    "    for cls in np.unique(y):\n",
    "        mask = y == cls\n",
    "        ax.scatter(features[mask, 0], features[mask, 1],\n",
    "                   s=point_size, c=colors[cls], alpha=alpha, linewidths=0)\n",
    "\n",
    "def scatter_by_prob(ax, features, prob, cls_idx, point_size):\n",
    "    ax.scatter(features[:, 0], features[:, 1],\n",
    "               s=point_size, c=prob[:, cls_idx],\n",
    "               cmap='bwr', vmin=0.0, vmax=1.0, alpha=alpha, linewidths=0)\n",
    "\n",
    "# ----- Global axis limits -----\n",
    "x_min, x_max = -3., 3.\n",
    "y_min, y_max = -4., 2.\n",
    "\n",
    "# ----- Figure: 6 rows x N columns -----\n",
    "n_cols = len(datasets)\n",
    "fig, axes = plt.subplots(6, n_cols, figsize=(6 * n_cols, 5 * 6),\n",
    "                         sharex=True, sharey=True)\n",
    "axes = np.array(axes).reshape(6, n_cols)\n",
    "\n",
    "for col, (title, feats, y_true, y_pred, prob) in enumerate(datasets):\n",
    "    # Compute point size per dataset\n",
    "    ps = compute_point_size(len(feats))\n",
    "\n",
    "    # Column title (big, spanning the column)\n",
    "    axes[0, col].set_title(title, fontsize=16, pad=20)\n",
    "\n",
    "    # Row 0: TRUE labels\n",
    "    ax_top = axes[0, col]\n",
    "    scatter_by_class(ax_top, feats, y_true, class_colors, ps)\n",
    "    ax_top.set_xlim(x_min, x_max)\n",
    "    ax_top.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Row 1: PREDICTED labels\n",
    "    ax_pred = axes[1, col]\n",
    "    scatter_by_class(ax_pred, feats, y_pred, class_colors, ps)\n",
    "\n",
    "    # Rows 2-5: Probabilities\n",
    "    for cls_idx in range(4):\n",
    "        ax_prob = axes[2 + cls_idx, col]\n",
    "        scatter_by_prob(ax_prob, feats, prob, cls_idx, ps)\n",
    "\n",
    "# Hide tick labels for internal subplots\n",
    "for i in range(6):\n",
    "    for j in range(n_cols):\n",
    "        ax = axes[i, j]\n",
    "        if i < 5:  # Hide x tick labels for rows above bottom row\n",
    "            ax.set_xticklabels([])\n",
    "        if j > 0:  # Hide y tick labels for columns beyond first\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "# Set axis labels only on outer plots\n",
    "for ax in axes[-1, :]:  # Bottom row x-labels\n",
    "    ax.set_xlabel(\"Feature 1\")\n",
    "for ax in axes[:, 0]:   # Leftmost column y-labels\n",
    "    ax.set_ylabel(\"Feature 2\")\n",
    "\n",
    "# Legend for classes\n",
    "class_lines = [mpl.lines.Line2D([0], [0], color=class_colors[k], marker='o',\n",
    "                                linestyle='', markersize=8, label=class_names[k])\n",
    "               for k in sorted(class_names.keys())]\n",
    "fig.legend(class_lines, [class_names[k] for k in sorted(class_names.keys())],\n",
    "           loc='upper right', title=\"Classes\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_key=\"DESI_FLUX_R\"\n",
    "mag_bin_edges=(17, 19, 21, 22, 22.5)\n",
    "output_key=\"MAG_BIN_ID\"\n",
    "\n",
    "magnitude_ranges = [(mag_bin_edges[i], mag_bin_edges[i+1]) for i in range(len(mag_bin_edges)-1)]\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "colormaps = [plt.cm.Blues, plt.cm.Greens, plt.cm.YlOrBr, plt.cm.Reds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_no_DA = evaluation_tools.add_magnitude_bins_to_results(\n",
    "    RESULTS_no_DA, magnitude_key=magnitude_key, mag_bin_edges=mag_bin_edges, output_key=output_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DA = evaluation_tools.add_magnitude_bins_to_results(\n",
    "    RESULTS_DA, magnitude_key=magnitude_key, mag_bin_edges=mag_bin_edges, output_key=output_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes_val_DESI = -2.5 * np.log10(RESULTS_no_DA[ii_model]['val_DESI_only']['DESI_FLUX_R']) + 22.5\n",
    "\n",
    "masks_all = plotting_utils.plot_histogram_with_ranges_multiple(\n",
    "    magnitudes_val_DESI, ranges=magnitude_ranges, colors=colors, bins=42,\n",
    "    x_label=\"DESI Magnitude (R)\",\n",
    "    title=\"DESI R-band Magnitudes by Dataset Split and Loader\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = [f\"{lo}‚Äì{hi}\" for lo, hi in magnitude_ranges]\n",
    "num_bins = len(magnitude_ranges)\n",
    "\n",
    "# Sweep no-DA models\n",
    "for model_idx, model_outputs in RESULTS_no_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        mag_bins = result[\"MAG_BIN_ID\"]\n",
    "        yy_true_all = result[\"true\"]\n",
    "        yy_pred_all = result[\"prob\"]\n",
    "\n",
    "        for bin_id in range(num_bins):\n",
    "            mask = mag_bins == bin_id\n",
    "            if np.sum(mask) == 0:\n",
    "                continue  # Skip empty bins\n",
    "\n",
    "            yy_true = yy_true_all[mask]\n",
    "            yy_pred = yy_pred_all[mask]\n",
    "\n",
    "            evaluation_tools.plot_confusion_matrix(\n",
    "                yy_true,\n",
    "                yy_pred,\n",
    "                class_names=class_names,\n",
    "                cmap=colormaps[bin_id],\n",
    "                title=f\"{key.replace('_', ' ')} (no-DA {model_idx}) | Mag {bin_labels[bin_id]}\"\n",
    "            )\n",
    "\n",
    "# Sweep DA models\n",
    "for model_idx, model_outputs in RESULTS_DA.items():\n",
    "    for key, result in model_outputs.items():\n",
    "        mag_bins = result[\"MAG_BIN_ID\"]\n",
    "        yy_true_all = result[\"true\"]\n",
    "        yy_pred_all = result[\"prob\"]\n",
    "\n",
    "        for bin_id in range(num_bins):\n",
    "            mask = mag_bins == bin_id\n",
    "            if np.sum(mask) == 0:\n",
    "                continue  # Skip empty bins\n",
    "\n",
    "            yy_true = yy_true_all[mask]\n",
    "            yy_pred = yy_pred_all[mask]\n",
    "\n",
    "            evaluation_tools.plot_confusion_matrix(\n",
    "                yy_true,\n",
    "                yy_pred,\n",
    "                class_names=class_names,\n",
    "                cmap=colormaps[bin_id],\n",
    "                title=f\"{key.replace('_', ' ')} (DA {model_idx}) | Mag {bin_labels[bin_id]}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
