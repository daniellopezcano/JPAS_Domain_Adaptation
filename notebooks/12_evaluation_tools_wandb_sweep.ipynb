{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL\n",
    "\n",
    "from JPAS_DA.data import data_loaders\n",
    "from JPAS_DA.data import wrapper_data_loaders\n",
    "from JPAS_DA.models import model_building_tools\n",
    "from JPAS_DA.training import training_tools\n",
    "from JPAS_DA.training import save_load_tools\n",
    "from JPAS_DA.evaluation import evaluation_tools\n",
    "from JPAS_DA.wrapper_wandb import wrapper_tools\n",
    "from JPAS_DA.evaluation import wandb_evaluation_tools\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "from JPAS_DA.utils import plotting_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "font, rcnew = plotting_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib widget\n",
    "\n",
    "from JPAS_DA.utils import aux_tools\n",
    "aux_tools.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wandb_sweep_no_DA = '/home/dlopez/Documents/Projects/JPAS_Domain_Adaptation/SAVED_models/11_wandb_no_DA'\n",
    "path_wandb_sweep_DA = '/home/dlopez/Documents/Projects/JPAS_Domain_Adaptation/SAVED_models/11_wandb_DA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list_sweep_names_no_DA, sorted_losses_no_DA = wandb_evaluation_tools.load_and_plot_sorted_sweeps(path_wandb_sweep_no_DA, max_runs_to_plot=3)\n",
    "sorted_list_sweep_names_DA, sorted_losses_DA = wandb_evaluation_tools.load_and_plot_sorted_sweeps(path_wandb_sweep_DA, max_runs_to_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_no_DA = os.path.join(path_wandb_sweep_no_DA, sorted_list_sweep_names_no_DA[0])\n",
    "path_load_DA = os.path.join(path_wandb_sweep_DA, sorted_list_sweep_names_DA[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_encoder_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_no_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_no_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "\n",
    "_, model_encoder_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_encoder.pt\"), model_building_tools.create_mlp)\n",
    "_, model_downstream_DA = save_load_tools.load_model_from_checkpoint(os.path.join(path_load_DA, \"model_downstream.pt\"), model_building_tools.create_mlp)\n",
    "\n",
    "_ = evaluation_tools.compare_model_parameters(model_downstream_no_DA, model_downstream_DA, rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_no_DA = wrapper_tools.load_config_file(os.path.join(path_load_no_DA, \"config.yaml\"))\n",
    "config_DA = wrapper_tools.load_config_file(os.path.join(path_load_DA, \"config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = config_no_DA[\"data\"]\n",
    "dict_data_DA = config_DA[\"data\"]\n",
    "\n",
    "assert isinstance(dict_data, dict) and isinstance(dict_data_DA, dict), \"Both inputs must be dictionaries.\"\n",
    "assert dict_data == dict_data_DA, f\"‚ùå Dictionaries differ!\\nExpected:\\n{dict_data}\\n\\nGot:\\n{dict_data_DA}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = save_load_tools.load_means_stds(path_load_no_DA)\n",
    "dict_data[\"provided_normalization\"] = (means, stds)\n",
    "\n",
    "dset_loaders = wrapper_data_loaders.wrapper_data_loaders(**dict_data)\n",
    "dset_val_no_DA = dset_loaders['DESI_combined']['val']\n",
    "dset_val_DA = dset_loaders['JPAS_matched']['val']\n",
    "dset_test = dset_loaders['JPAS_matched']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy_true = dset_val_no_DA(batch_size=dset_val_no_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "yy_true_val_no_DA = yy_true.cpu().numpy()\n",
    "features_val_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_no_DA = np.argmax(yy_pred_P_val_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_val_DA(batch_size=dset_val_DA.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "yy_true_val_DA = yy_true.cpu().numpy()\n",
    "features_val_DA = features_.cpu().numpy()\n",
    "yy_pred_P_val_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_val_DA = np.argmax(yy_pred_P_val_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_no_DA(xx)\n",
    "        logits = model_downstream_no_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_no_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_no_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_no_DA = np.argmax(yy_pred_P_test_no_DA, axis=1)\n",
    "\n",
    "\n",
    "xx, yy_true = dset_test(batch_size=dset_test.NN_xx, seed=0, sampling_strategy=\"true_random\", to_torch=True, device=\"cpu\")\n",
    "with torch.no_grad():\n",
    "        features_ = model_encoder_DA(xx)\n",
    "        logits = model_downstream_DA(features_)\n",
    "yy_pred_P = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "yy_true_test = yy_true.cpu().numpy()\n",
    "features_test_DA = features_.cpu().numpy()\n",
    "yy_pred_P_test_DA = yy_pred_P.cpu().numpy()\n",
    "yy_pred_test_DA = np.argmax(yy_pred_P_test_DA, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(dset_test.class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.plot_confusion_matrix(\n",
    "    yy_true_val_no_DA, yy_pred_P_val_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"val no DA\"\n",
    ")\n",
    "\n",
    "plotting_utils.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"test no DA\"\n",
    ")\n",
    "\n",
    "plotting_utils.plot_confusion_matrix(\n",
    "    yy_true_val_DA, yy_pred_P_val_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"val DA\"\n",
    ")\n",
    "\n",
    "plotting_utils.plot_confusion_matrix(\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    cmap=plt.cm.RdYlGn, title=\"test DA\"\n",
    ")\n",
    "\n",
    "plotting_utils.compare_TPR_confusion_matrices(\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_no_DA,\n",
    "    yy_true_test,\n",
    "    yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    figsize=(10, 7),\n",
    "    cmap='seismic',\n",
    "    title='TPR Comparison: DA vs no DA',\n",
    "    name_1 = \"no DA\",\n",
    "    name_2 = \"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_utils.compare_sets_performance(\n",
    "    yy_true_test, yy_pred_P_test_no_DA,\n",
    "    yy_true_test, yy_pred_P_test_DA,\n",
    "    class_names=np.arange(n_classes),\n",
    "    name_1=\"no DA\",\n",
    "    name_2=\"DA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# === Stack all feature representations together ===\n",
    "n_val_no_DA = features_val_no_DA.shape[0]\n",
    "n_val_DA = features_val_DA.shape[0]\n",
    "n_test_no_DA = features_test_no_DA.shape[0]\n",
    "n_test_DA = features_test_DA.shape[0]\n",
    "\n",
    "X_all = np.vstack([\n",
    "    features_val_no_DA,\n",
    "    features_val_DA,\n",
    "    features_test_no_DA,\n",
    "    features_test_DA\n",
    "])\n",
    "\n",
    "# === Perform shared t-SNE projection ===\n",
    "tsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\n",
    "X_all_tsne = tsne.fit_transform(X_all)\n",
    "\n",
    "# === Split back to original domains ===\n",
    "i0 = 0\n",
    "i1 = i0 + n_val_no_DA\n",
    "i2 = i1 + n_val_DA\n",
    "i3 = i2 + n_test_no_DA\n",
    "i4 = i3 + n_test_DA\n",
    "\n",
    "X_val_no_DA_tsne   = X_all_tsne[i0:i1]\n",
    "X_val_DA_tsne      = X_all_tsne[i1:i2]\n",
    "X_test_no_DA_tsne  = X_all_tsne[i2:i3]\n",
    "X_test_DA_tsne     = X_all_tsne[i3:i4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import binned_statistic_2d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# === Use consistent labels and colors ===\n",
    "y_all = np.concatenate([yy_true_val_no_DA, yy_true_val_DA, yy_true_test, yy_true_test])\n",
    "unique_classes = np.unique(y_all)\n",
    "cmap = plt.cm.get_cmap(\"tab10\")\n",
    "class_color_dict = {cls: cmap(i) for i, cls in enumerate(unique_classes)}\n",
    "class_rgb = np.array([class_color_dict[cls][:3] for cls in unique_classes])\n",
    "\n",
    "# === Class counts and inverse-frequency weights ===\n",
    "class_counts = dset_test.class_counts\n",
    "inv_freq_weights = 1 / class_counts\n",
    "inv_freq_weights = inv_freq_weights / np.sum(inv_freq_weights)\n",
    "assert len(inv_freq_weights) == len(unique_classes)\n",
    "\n",
    "# === Datasets to plot ===\n",
    "datasets = [\n",
    "    (\"Validation Domain (No DA)\", X_val_no_DA_tsne, yy_true_val_no_DA),\n",
    "    (\"Test Domain (No DA)\",       X_test_no_DA_tsne, yy_true_test),\n",
    "    (\"Validation Domain (With DA)\", X_val_DA_tsne, yy_true_val_DA),\n",
    "    (\"Test Domain (With DA)\",     X_test_DA_tsne, yy_true_test),\n",
    "]\n",
    "\n",
    "# === Create figure and determine bounds ===\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12), sharex=True, sharey=True)\n",
    "all_points = np.vstack([X for _, X, _ in datasets])\n",
    "x_min, x_max = np.min(all_points[:, 0]), np.max(all_points[:, 0])\n",
    "y_min, y_max = np.min(all_points[:, 1]), np.max(all_points[:, 1])\n",
    "n_bins = 128\n",
    "sigma = 2.0\n",
    "\n",
    "# === Plot each dataset ===\n",
    "for ax, (title, X_emb, y_labels) in zip(axs.ravel(), datasets):\n",
    "    ax.set_title(f\"t-SNE: {title}\", fontsize=14)\n",
    "    ax.set_xlabel(\"t-SNE 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"t-SNE 2\", fontsize=12)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.tick_params(labelsize=10)\n",
    "\n",
    "    # Grid counting per class\n",
    "    H_class = np.zeros((n_bins, n_bins, len(unique_classes)))\n",
    "    for i, cls in enumerate(unique_classes):\n",
    "        idx = y_labels == cls\n",
    "        if np.sum(idx) == 0:\n",
    "            continue\n",
    "        stat, _, _, _ = binned_statistic_2d(\n",
    "            X_emb[idx, 0], X_emb[idx, 1], None,\n",
    "            statistic='count', bins=n_bins,\n",
    "            range=[[x_min, x_max], [y_min, y_max]]\n",
    "        )\n",
    "        stat = gaussian_filter(stat.T, sigma=sigma)\n",
    "        H_class[:, :, i] = stat * inv_freq_weights[i]\n",
    "\n",
    "        ax.scatter(X_emb[idx, 0], X_emb[idx, 1], color=class_color_dict[cls], label=f\"Class {cls}\", s=0.05, alpha=0.8)\n",
    "\n",
    "    # Blend RGB according to class composition\n",
    "    H_total = np.sum(H_class, axis=2, keepdims=True)\n",
    "    proportions = np.divide(H_class, H_total, out=np.zeros_like(H_class), where=H_total != 0)\n",
    "    image_rgb = np.tensordot(proportions, class_rgb, axes=(2, 0))\n",
    "\n",
    "    # === Improved density modulation ===\n",
    "    density = H_total.squeeze()\n",
    "    # === Logarithmic brightness modulation ===\n",
    "    eps = 1e-3  # to avoid log(0)\n",
    "    density_log = np.log1p(density / eps)\n",
    "    panel_max = np.max(density_log)\n",
    "    if panel_max > 0:\n",
    "        density_mod = density_log / panel_max\n",
    "    else:\n",
    "        density_mod = density_log  # all zeros, just skip scaling\n",
    "    density_mod[density < eps] = 0  # force very empty bins to black\n",
    "    image_rgb *= density_mod[..., None]\n",
    "\n",
    "    ax.imshow(image_rgb, extent=[x_min, x_max, y_min, y_max],\n",
    "              origin='lower', aspect='auto', interpolation='nearest')\n",
    "\n",
    "# === Legend ===\n",
    "legend_elements = [\n",
    "    mpatches.Patch(color=class_color_dict[cls], label=f\"Class {cls}\")\n",
    "    for cls in unique_classes\n",
    "]\n",
    "axs[0, 0].legend(handles=legend_elements, title=\"Class\", fontsize=10, title_fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
